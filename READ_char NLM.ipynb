{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We use char2char NLM using seq2seq + Attention model.\n",
    "\n",
    "The encoder-decoder follows seq2seq model.\n",
    "\n",
    "The decoding is based on attending to the encoder + the current decoder state.\n",
    "The attention model follows: Luong et al., 2015 (https://arxiv.org/abs/1508.04025) instead of the traditional Bahadanau et al., 2014 (https://arxiv.org/abs/1409.0473). The implementation of attention follows this blog: https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html. The reason to choose that is that the attention level is working at the output level of the LSTM, while Bahdanau attention needs to work at the state level of the encoder.\n",
    "\n",
    "Planning to move to Attention() layer from fast.ai Jeremy Howard implementation: https://github.com/fastai/courses/blob/master/deeplearning2/attention_wrapper.py, which is following Bahdanau attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import *\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpu_alloc(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '.'\n",
    "file_name = 'wonderland.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALICE'S ADVENTURES IN WONDERLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "full_file_name = os.path.join(data_path, file_name)\n",
    "raw_texts = load_data(full_file_name, num_samples)\n",
    "print(raw_texts[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "in_seq_len = 20\n",
    "out_seq_len = 20\n",
    "input_texts, target_texts = generate_lm_data(raw_texts, in_seq_len, out_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86641\n",
      "ALICE'S ADVENTURES I \n",
      " \tN WONDERLAND\n",
      "\n",
      "Lewis \n",
      "\n",
      "LICE'S ADVENTURES IN \n",
      " \t WONDERLAND\n",
      "\n",
      "Lewis C\n",
      "\n",
      "ICE'S ADVENTURES IN  \n",
      " \tWONDERLAND\n",
      "\n",
      "Lewis Ca\n",
      "\n",
      "CE'S ADVENTURES IN W \n",
      " \tONDERLAND\n",
      "\n",
      "Lewis Car\n",
      "\n",
      "E'S ADVENTURES IN WO \n",
      " \tNDERLAND\n",
      "\n",
      "Lewis Carr\n",
      "\n",
      "'S ADVENTURES IN WON \n",
      " \tDERLAND\n",
      "\n",
      "Lewis Carro\n",
      "\n",
      "S ADVENTURES IN WOND \n",
      " \tERLAND\n",
      "\n",
      "Lewis Carrol\n",
      "\n",
      " ADVENTURES IN WONDE \n",
      " \tRLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "ADVENTURES IN WONDER \n",
      " \tLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "\n",
      "DVENTURES IN WONDERL \n",
      " \tAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = target_texts + input_texts\n",
    "vocab_to_int, int_to_vocab = build_vocab(all_texts)\n",
    "np.savez('vocab-{}', vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts]) + 2 # For '\\t' and '\\n'\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts]) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 86641\n",
      "Number of unique input tokens: 72\n",
      "Number of unique output tokens: 72\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 24\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '!': 61,\n",
       " '\"': 64,\n",
       " \"'\": 46,\n",
       " '(': 49,\n",
       " ')': 50,\n",
       " '*': 65,\n",
       " ',': 42,\n",
       " '-': 51,\n",
       " '.': 28,\n",
       " '0': 29,\n",
       " '3': 27,\n",
       " ':': 43,\n",
       " ';': 54,\n",
       " '?': 47,\n",
       " 'A': 11,\n",
       " 'B': 66,\n",
       " 'C': 16,\n",
       " 'D': 7,\n",
       " 'E': 8,\n",
       " 'F': 26,\n",
       " 'G': 60,\n",
       " 'H': 22,\n",
       " 'I': 24,\n",
       " 'J': 67,\n",
       " 'K': 56,\n",
       " 'L': 10,\n",
       " 'M': 23,\n",
       " 'N': 4,\n",
       " 'O': 6,\n",
       " 'P': 30,\n",
       " 'Q': 68,\n",
       " 'R': 9,\n",
       " 'S': 57,\n",
       " 'T': 21,\n",
       " 'U': 25,\n",
       " 'UNK': 0,\n",
       " 'V': 52,\n",
       " 'W': 5,\n",
       " 'Y': 53,\n",
       " 'Z': 62,\n",
       " '[': 69,\n",
       " ']': 70,\n",
       " '_': 71,\n",
       " 'a': 17,\n",
       " 'b': 32,\n",
       " 'c': 31,\n",
       " 'd': 38,\n",
       " 'e': 12,\n",
       " 'f': 39,\n",
       " 'g': 33,\n",
       " 'h': 40,\n",
       " 'i': 14,\n",
       " 'j': 58,\n",
       " 'k': 41,\n",
       " 'l': 20,\n",
       " 'm': 48,\n",
       " 'n': 34,\n",
       " 'o': 19,\n",
       " 'p': 44,\n",
       " 'q': 55,\n",
       " 'r': 18,\n",
       " 's': 15,\n",
       " 't': 35,\n",
       " 'u': 45,\n",
       " 'v': 36,\n",
       " 'w': 13,\n",
       " 'x': 59,\n",
       " 'y': 37,\n",
       " 'z': 63}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int # Some special chars need to be removed TODO: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'N',\n",
       " 5: 'W',\n",
       " 6: 'O',\n",
       " 7: 'D',\n",
       " 8: 'E',\n",
       " 9: 'R',\n",
       " 10: 'L',\n",
       " 11: 'A',\n",
       " 12: 'e',\n",
       " 13: 'w',\n",
       " 14: 'i',\n",
       " 15: 's',\n",
       " 16: 'C',\n",
       " 17: 'a',\n",
       " 18: 'r',\n",
       " 19: 'o',\n",
       " 20: 'l',\n",
       " 21: 'T',\n",
       " 22: 'H',\n",
       " 23: 'M',\n",
       " 24: 'I',\n",
       " 25: 'U',\n",
       " 26: 'F',\n",
       " 27: '3',\n",
       " 28: '.',\n",
       " 29: '0',\n",
       " 30: 'P',\n",
       " 31: 'c',\n",
       " 32: 'b',\n",
       " 33: 'g',\n",
       " 34: 'n',\n",
       " 35: 't',\n",
       " 36: 'v',\n",
       " 37: 'y',\n",
       " 38: 'd',\n",
       " 39: 'f',\n",
       " 40: 'h',\n",
       " 41: 'k',\n",
       " 42: ',',\n",
       " 43: ':',\n",
       " 44: 'p',\n",
       " 45: 'u',\n",
       " 46: \"'\",\n",
       " 47: '?',\n",
       " 48: 'm',\n",
       " 49: '(',\n",
       " 50: ')',\n",
       " 51: '-',\n",
       " 52: 'V',\n",
       " 53: 'Y',\n",
       " 54: ';',\n",
       " 55: 'q',\n",
       " 56: 'K',\n",
       " 57: 'S',\n",
       " 58: 'j',\n",
       " 59: 'x',\n",
       " 60: 'G',\n",
       " 61: '!',\n",
       " 62: 'Z',\n",
       " 63: 'z',\n",
       " 64: '\"',\n",
       " 65: '*',\n",
       " 66: 'B',\n",
       " 67: 'J',\n",
       " 68: 'Q',\n",
       " 69: '[',\n",
       " 70: ']',\n",
       " 71: '_'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sentences\n",
    "input_texts, test_input_texts, target_texts, test_target_texts  = train_test_split(input_texts, target_texts, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = vectorize_data(input_texts=input_texts,\n",
    "                                                                             target_texts=target_texts, \n",
    "                                                                             max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                             num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                             vocab_to_int=vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73644, 22)\n",
      "(73644, 22, 72)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_input_data, test_decoder_input_data, test_decoder_target_data = vectorize_data(input_texts=test_input_texts,\n",
    "                                                                                            target_texts=test_target_texts, \n",
    "                                                                                            max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                                            num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                                            vocab_to_int=vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'concatenate_1/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 512) dtype=float32>]\n",
      "Tensor(\"lstm_2/transpose_2:0\", shape=(?, ?, 512), dtype=float32)\n",
      "Tensor(\"bidirectional_1/concat:0\", shape=(?, ?, 512), dtype=float32)\n",
      "attention Tensor(\"attention/truediv:0\", shape=(?, ?, ?), dtype=float32)\n",
      "encoder-decoder  model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 72)     5184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, None, 512),  673792      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 72)     5184        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1198080     embedding_2[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1024)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 72)     73800       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,956,040\n",
      "Trainable params: 1,945,672\n",
      "Non-trainable params: 10,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Tensor(\"input_1:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"bidirectional_1/concat:0\", shape=(?, ?, 512), dtype=float32)\n",
      "[<tf.Tensor 'concatenate_1/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 512) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elsallab/Work/cod/READ/utils.py:455: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  encoder_model = Model(input=encoder_inputs, output=[encoder_outputs] + encoder_states)\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = build_model(latent_dim=latent_dim, num_encoder_tokens=num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 20  \n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_model.hdf5\" # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "#lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "#lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks_list.append(lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66279 samples, validate on 7365 samples\n",
      "Epoch 1/20\n",
      "66279/66279 [==============================] - 100s 2ms/step - loss: 1.6423 - categorical_accuracy: 0.4861 - val_loss: 1.2215 - val_categorical_accuracy: 0.5883\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.58832, saving model to best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 1.0743 - categorical_accuracy: 0.6279 - val_loss: 0.9854 - val_categorical_accuracy: 0.6509\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.58832 to 0.65087, saving model to best_model.hdf5\n",
      "Epoch 3/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.9112 - categorical_accuracy: 0.6709 - val_loss: 0.8806 - val_categorical_accuracy: 0.6801\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.65087 to 0.68015, saving model to best_model.hdf5\n",
      "Epoch 4/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.8196 - categorical_accuracy: 0.6967 - val_loss: 0.8144 - val_categorical_accuracy: 0.6995\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.68015 to 0.69955, saving model to best_model.hdf5\n",
      "Epoch 5/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.7551 - categorical_accuracy: 0.7154 - val_loss: 0.7578 - val_categorical_accuracy: 0.7160\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.69955 to 0.71596, saving model to best_model.hdf5\n",
      "Epoch 6/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.7023 - categorical_accuracy: 0.7310 - val_loss: 0.7316 - val_categorical_accuracy: 0.7228\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.71596 to 0.72282, saving model to best_model.hdf5\n",
      "Epoch 7/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.6634 - categorical_accuracy: 0.7424 - val_loss: 0.6919 - val_categorical_accuracy: 0.7368\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.72282 to 0.73676, saving model to best_model.hdf5\n",
      "Epoch 8/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.6189 - categorical_accuracy: 0.7559 - val_loss: 0.6593 - val_categorical_accuracy: 0.7465\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.73676 to 0.74652, saving model to best_model.hdf5\n",
      "Epoch 9/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.5855 - categorical_accuracy: 0.7659 - val_loss: 0.6385 - val_categorical_accuracy: 0.7531\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.74652 to 0.75306, saving model to best_model.hdf5\n",
      "Epoch 10/20\n",
      "66279/66279 [==============================] - 97s 1ms/step - loss: 0.5550 - categorical_accuracy: 0.7749 - val_loss: 0.6205 - val_categorical_accuracy: 0.7573\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.75306 to 0.75728, saving model to best_model.hdf5\n",
      "Epoch 11/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.5420 - categorical_accuracy: 0.7783 - val_loss: 0.6155 - val_categorical_accuracy: 0.7591\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.75728 to 0.75909, saving model to best_model.hdf5\n",
      "Epoch 12/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.5161 - categorical_accuracy: 0.7865 - val_loss: 0.5773 - val_categorical_accuracy: 0.7714\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.75909 to 0.77137, saving model to best_model.hdf5\n",
      "Epoch 13/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.4974 - categorical_accuracy: 0.7921 - val_loss: 0.5781 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.77137\n",
      "Epoch 14/20\n",
      "66279/66279 [==============================] - 97s 1ms/step - loss: 0.4828 - categorical_accuracy: 0.7966 - val_loss: 0.5701 - val_categorical_accuracy: 0.7746\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.77137 to 0.77463, saving model to best_model.hdf5\n",
      "Epoch 15/20\n",
      "66279/66279 [==============================] - 98s 1ms/step - loss: 0.4761 - categorical_accuracy: 0.7985 - val_loss: 0.5546 - val_categorical_accuracy: 0.7783\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.77463 to 0.77833, saving model to best_model.hdf5\n",
      "Epoch 16/20\n",
      "14080/66279 [=====>........................] - ETA: 1:14 - loss: 0.4330 - categorical_accuracy: 0.8122"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          #validation_data = ([test_encoder_input_data, test_decoder_input_data], test_decoder_target_data),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save('encoder_model.hdf5')\n",
    "decoder_model.save('decoder_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_text = input_texts[seq_index]\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    \n",
    "    \n",
    "    encoder_input_data, decoder_input_data, decoder_target_data = vectorize_data(input_texts=input_text,\n",
    "                                                                                 target_texts=target_text, \n",
    "                                                                                 max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                                 num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                                 vocab_to_int=vocab_to_int)    \n",
    "\n",
    "    input_seq = encoder_input_data\n",
    "    #target_seq = np.argmax(decoder_target_data, axis=-1)\n",
    "    #print(target_seq)\n",
    "    decoded_seq, _ = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, max_encoder_seq_length, int_to_vocab, vocab_to_int)\n",
    "    \n",
    "    decoded_sentence = ' '.join(decoded_seq) \n",
    "    print('-')\n",
    "    print('Input sentence:', input_text)\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(100):\n",
    "\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    text = input_texts[seq_index]\n",
    "    decoded_sentence = visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, vocab_to_int, int_to_vocab)\n",
    "    print('-')\n",
    "    print('Input sentence:', text)\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Short inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "corrected_sentences = []\n",
    "corrected_input_sentences = []\n",
    "results = open('RESULTS.md', 'w')\n",
    "results.write('|OCR sentence|GT sentence|Decoded sentence|\\n')\n",
    "results.write('|------------|-----------|----------------|\\n')\n",
    "for seq_index in range(len(test_input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_text = test_input_texts[seq_index]\n",
    "    target_text = test_target_texts[seq_index][1:-1]\n",
    "\n",
    "    encoder_input_data, decoder_input_data, decoder_target_data = vectorize_data(input_texts=input_text,\n",
    "                                                                                 target_texts=target_text, \n",
    "                                                                                 max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                                 num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                                 vocab_to_int=vocab_to_int)    \n",
    "\n",
    "    input_seq = encoder_input_data\n",
    "    #target_seq = np.argmax(decoder_target_data, axis=-1)\n",
    "    #print(target_seq)\n",
    "    decoded_sentence, _ = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, max_encoder_seq_length, int_to_vocab, vocab_to_int)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text)\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    results.write(' | ' + input_text + ' | ' + target_text.strip() + ' | ' + decoded_sentence + ' | \\n')\n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    corrected_sentences.append(corrected_sentence)\n",
    "    corrected_input_sentences.append(corrected_input_sentence)\n",
    "    target_texts_.append(target_text)\n",
    "\n",
    "\n",
    "encoder_input_data = vectorize_data(input_texts=input_texts, max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens, vocab_to_int=vocab_to_int)\n",
    "    \n",
    "results.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for seq_index in range(100):\n",
    "    target_text = test_target_texts[seq_index][1:-1]\n",
    "    text = test_input_texts[seq_index]\n",
    "\n",
    "    decoded_sentence = visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, vocab_to_int, int_to_vocab)\n",
    "    print('-')\n",
    "    print('Input sentence:', text)\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
