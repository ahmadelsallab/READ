{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding, Lambda, Concatenate, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentences_data(input_texts, target_labels, max_sents_per_doc, max_words_per_sent, max_chars_per_word, \n",
    "                             num_classes, char2int):\n",
    "\n",
    "    \n",
    "    \n",
    "    hier_input_data = np.zeros((len(input_texts), \n",
    "                                max_sents_per_doc, \n",
    "                                max_words_per_sent, \n",
    "                                max_chars_per_word), dtype='float32')\n",
    "    \n",
    "        \n",
    "    hier_target_data = np.zeros((len(input_texts), num_classes), dtype='float32')\n",
    "    if(target_labels == None):\n",
    "        target_labels = np.zeros(len(input_texts), dtype='int32')\n",
    "    \n",
    "    for i, (input_text, target_label) in enumerate(zip(input_texts, target_labels)):\n",
    "        #sents_lst = sent_tokenize(clean_str(BeautifulSoup(input_text).get_text())) # TODO: Move to clean str\n",
    "        sents_lst = sent_tokenize(input_text)\n",
    "        \n",
    "        \n",
    "        if len(sents_lst) > max_sents_per_doc:\n",
    "            continue\n",
    "        \n",
    "        for j, sent in enumerate(sents_lst):\n",
    "                \n",
    "            words_lst = word_tokenize(input_text)\n",
    "            \n",
    "            if(len(words_lst) > max_words_per_sent):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            for k, word in enumerate(words_lst):\n",
    "                \n",
    "                \n",
    "                if(len(word) > max_chars_per_word):\n",
    "                    continue\n",
    "                \n",
    "                for l, char in enumerate(word):\n",
    "                    # c0..cn\n",
    "                    if(char in char2int):\n",
    "                        hier_input_data[i, j, k, l] = char2int[char]\n",
    "                        try:\n",
    "                            hier_target_data[i, target_label] = 1\n",
    "                        except:\n",
    "                            print(target_label)\n",
    "\n",
    "                \n",
    "    return hier_input_data, hier_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars2word_model_simple_BiLSTM(num_encoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(encoder_inputs)    \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    " \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_word_embedding_model = Model(input=encoder_inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len, \n",
    "                           latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "\n",
    "    inputs = Input(shape=(max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    #print(inputs.shape)\n",
    "    input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "    encoder_inputs_ = input_words   \n",
    "    #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "        \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_sentence_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_sentence_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                         max_sents_seq_len, \n",
    "                         max_words_seq_len, \n",
    "                         max_char_seq_len, \n",
    "                         word2sent_latent_dim,\n",
    "                         sent2doc_latent_dim):\n",
    "    \n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    \n",
    "    sents_states = []\n",
    "    \n",
    "    for s in range(max_sents_seq_len):\n",
    "        \n",
    "        encoder_words_inputs = Lambda(lambda x: x[:,s,:,:])(inputs)\n",
    "        #print(encoder_words_inputs.shape)\n",
    "        encoder_words_outputs = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        encoder_words_outputs = Reshape((1,word2sent_latent_dim*2))(encoder_words_outputs)\n",
    "        #_, h, c = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        '''\n",
    "        input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "        encoder_inputs_ = input_words   \n",
    "        #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "        encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "        encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "\n",
    "        encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #encoder_words_states = Concatenate()([h,c])\n",
    "        #print(encoder_chars_states)\n",
    "        #encoder_words_states = Reshape((1,word2sent_latent_dim*4))(encoder_words_states)\n",
    "        #print(encoder_words_outputs.shape)\n",
    "        sents_states.append(encoder_words_outputs)\n",
    "    print(sents_states[0]._keras_shape)\n",
    "    input_sents = Concatenate(axis=-2)(sents_states)\n",
    "    #print(input_sents.shape)\n",
    "    encoder_inputs_ = input_sents   \n",
    "    encoder = Bidirectional(LSTM(sent2doc_latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    \n",
    "    encoder_document_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "    '''\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    '''\n",
    "    #return model, encoder_document_embedding_model\n",
    "    return encoder_document_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hier_senti_model(encoder_document_embedding_model,\n",
    "                           max_sents_seq_len, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len):\n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    encoder_embedding_output = encoder_document_embedding_model(inputs)\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/labeledTrainData.tsv'\n",
    "data_train = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/testData.tsv'\n",
    "data_test = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      With all this stuff going down at the moment w...\n",
       "1      \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2      The film starts with a manager (Nicholas Bell)...\n",
       "3      It must be assumed that those who praised this...\n",
       "4      Superbly trashy and wondrously unpretentious 8...\n",
       "5      I dont know why people think this is such a ba...\n",
       "6      This movie could have been very good, but come...\n",
       "7      I watched this video at a friend's house. I'm ...\n",
       "8      A friend of mine bought this film for £1, and ...\n",
       "9      <br /><br />This movie is full of references. ...\n",
       "10     What happens when an army of wetbacks, towelhe...\n",
       "11     Although I generally do not like remakes belie...\n",
       "12     \\Mr. Harvey Lights a Candle\\\" is anchored by a...\n",
       "13     I had a feeling that after \\Submerged\\\", this ...\n",
       "14     note to George Litman, and others: the Mystery...\n",
       "15     Stephen King adaptation (scripted by King hims...\n",
       "16     `The Matrix' was an exciting summer blockbuste...\n",
       "17     Ulli Lommel's 1980 film 'The Boogey Man' is no...\n",
       "18     This movie is one among the very few Indian mo...\n",
       "19     Most people, especially young people, may not ...\n",
       "20     \\Soylent Green\\\" is one of the best and most d...\n",
       "21     Michael Stearns plays Mike, a sexually frustra...\n",
       "22     This happy-go-luck 1939 military swashbuckler,...\n",
       "23     I would love to have that two hours of my life...\n",
       "24     The script for this movie was probably found i...\n",
       "25     Looking for Quo Vadis at my local video store,...\n",
       "26     Note to all mad scientists everywhere: if you'...\n",
       "27     What the ........... is this ? This must, with...\n",
       "28     Intrigued by the synopsis (every gay video the...\n",
       "29     Would anyone really watch this RUBBISH if it d...\n",
       "                             ...                        \n",
       "970    This movie was disaster at Box Office, and the...\n",
       "971    8 Simple Rules is a funny show but it also has...\n",
       "972    This movie was strange... I watched it while i...\n",
       "973    *** Contains Spoilers ***<br /><br />I did not...\n",
       "974    ...for this movie defines a new low in Bollywo...\n",
       "975    This dreadful film assembles every Asian stere...\n",
       "976    The original movie, The Odd Couple, has some w...\n",
       "977    Gédéon and Jules Naudet wanted to film a docum...\n",
       "978    \\Hotel du Nord \\\" is the only Carné movie from...\n",
       "979    One of Boris Karloff's real clinkers. Essentia...\n",
       "980    It is not every film's job to stimulate you su...\n",
       "981    LOL! Not a bad way to start it. I thought this...\n",
       "982    Modern viewers know this little film primarily...\n",
       "983    Like most comments I saw this film under the n...\n",
       "984    Diana Guzman is an angry young woman. Survivin...\n",
       "985    Rated PG-13 for violence, brief sexual humor a...\n",
       "986    First of all yes I'm white, so I try to tread ...\n",
       "987    A film that is so much a 30's Warners film in ...\n",
       "988    Though I'm not the biggest fan of wirework bas...\n",
       "989    I have to totally disagree with the other comm...\n",
       "990    I picked this movie up to replace the dismal c...\n",
       "991    Usually, any film with Sylvester Stallone is u...\n",
       "992    This is a VERY entertaining movie. A few of th...\n",
       "993    Think Pierce Brosnan and you think suave, dapp...\n",
       "994    A new way to enjoy Goldsworthy's work, Rivers ...\n",
       "995    The only thing I remember about this movie are...\n",
       "996    This is a kind of movie that will stay with yo...\n",
       "997    I just didn't get this movie...Was it a musica...\n",
       "998    Granting the budget and time constraints of se...\n",
       "999    This move was on TV last night. I guess as a t...\n",
       "Name: review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = data_train.review  + data_test.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars_per_words_lengths = []\n",
    "words_per_sents_lengths = []\n",
    "sents_per_docs_lengths = []\n",
    "\n",
    "# Chars per word should be on all text\n",
    "\n",
    "for text in all_texts:\n",
    "    \n",
    "    sents = sent_tokenize(clean_str(BeautifulSoup(text).get_text()))\n",
    "    sents_per_docs_lengths.append(len(sents))\n",
    "    for sent in sents:       \n",
    "    \n",
    "        words = word_tokenize(text)\n",
    "        words_per_sents_lengths.append(len(words))\n",
    "        for word in words:\n",
    "            chars_per_words_lengths.append(len(word))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92e83fef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_s = plt.hist(sents_per_docs_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.800000000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.45303783595946"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92e035c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_w = plt.hist(words_per_sents_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677.36979797979802"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3067"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361.23638615703925"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92e06e5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_c = plt.hist(chars_per_words_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8788835783566293"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5373921840645841"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "all_texts = list(all_texts.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "train_texts = list(data_train.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n",
    "test_texts = list(data_test.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char vocab (all text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_to_int, int_to_vocab = build_chars_vocab(all_texts)\n",
    "#np.savez('vocab_char-{}'.format(max_sent_len), vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, max_sent_len=max_sent_len, min_sent_len=min_sent_len )\n",
    "char2int = vocab_to_int\n",
    "int2char = int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in all_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1000\n",
      "Number of unique input tokens: 108\n",
      "Number of unique output tokens: 108\n",
      "Max sequence length for inputs: 13235\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(all_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '!': 37,\n",
       " '#': 67,\n",
       " '$': 51,\n",
       " '%': 60,\n",
       " '&': 55,\n",
       " '(': 35,\n",
       " ')': 36,\n",
       " '*': 53,\n",
       " '+': 66,\n",
       " ',': 23,\n",
       " '-': 41,\n",
       " '.': 27,\n",
       " '/': 49,\n",
       " '0': 31,\n",
       " '1': 42,\n",
       " '2': 30,\n",
       " '3': 56,\n",
       " '4': 48,\n",
       " '5': 45,\n",
       " '6': 43,\n",
       " '7': 50,\n",
       " '8': 46,\n",
       " '9': 44,\n",
       " ':': 39,\n",
       " ';': 38,\n",
       " '<': 90,\n",
       " '=': 59,\n",
       " '>': 91,\n",
       " '?': 34,\n",
       " '@': 71,\n",
       " 'UNK': 0,\n",
       " '[': 62,\n",
       " ']': 63,\n",
       " '^': 89,\n",
       " '_': 72,\n",
       " '`': 57,\n",
       " 'a': 8,\n",
       " 'b': 28,\n",
       " 'c': 22,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 12,\n",
       " 'g': 13,\n",
       " 'h': 7,\n",
       " 'i': 5,\n",
       " 'j': 19,\n",
       " 'k': 26,\n",
       " 'l': 9,\n",
       " 'm': 18,\n",
       " 'n': 15,\n",
       " 'o': 14,\n",
       " 'p': 29,\n",
       " 'q': 33,\n",
       " 'r': 21,\n",
       " 's': 10,\n",
       " 't': 6,\n",
       " 'u': 11,\n",
       " 'v': 20,\n",
       " 'w': 4,\n",
       " 'x': 32,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " '{': 96,\n",
       " '|': 105,\n",
       " '}': 97,\n",
       " '~': 65,\n",
       " '\\x84': 70,\n",
       " '\\x85': 64,\n",
       " '\\x91': 102,\n",
       " '\\x96': 47,\n",
       " '\\x97': 73,\n",
       " '¡': 93,\n",
       " '£': 52,\n",
       " '¨': 40,\n",
       " '®': 83,\n",
       " '´': 54,\n",
       " '·': 106,\n",
       " '½': 82,\n",
       " 'à': 81,\n",
       " 'á': 75,\n",
       " 'â': 84,\n",
       " 'ã': 98,\n",
       " 'ä': 76,\n",
       " 'æ': 92,\n",
       " 'ç': 85,\n",
       " 'è': 68,\n",
       " 'é': 58,\n",
       " 'ê': 61,\n",
       " 'ï': 80,\n",
       " 'ñ': 101,\n",
       " 'ó': 69,\n",
       " 'ô': 107,\n",
       " 'ö': 86,\n",
       " 'ø': 104,\n",
       " 'ù': 87,\n",
       " 'ü': 88,\n",
       " 'ı': 74,\n",
       " '–': 78,\n",
       " '‘': 79,\n",
       " '’': 77,\n",
       " '“': 99,\n",
       " '”': 100,\n",
       " '…': 103,\n",
       " '、': 95,\n",
       " '，': 94}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'w',\n",
       " 5: 'i',\n",
       " 6: 't',\n",
       " 7: 'h',\n",
       " 8: 'a',\n",
       " 9: 'l',\n",
       " 10: 's',\n",
       " 11: 'u',\n",
       " 12: 'f',\n",
       " 13: 'g',\n",
       " 14: 'o',\n",
       " 15: 'n',\n",
       " 16: 'd',\n",
       " 17: 'e',\n",
       " 18: 'm',\n",
       " 19: 'j',\n",
       " 20: 'v',\n",
       " 21: 'r',\n",
       " 22: 'c',\n",
       " 23: ',',\n",
       " 24: 'y',\n",
       " 25: 'z',\n",
       " 26: 'k',\n",
       " 27: '.',\n",
       " 28: 'b',\n",
       " 29: 'p',\n",
       " 30: '2',\n",
       " 31: '0',\n",
       " 32: 'x',\n",
       " 33: 'q',\n",
       " 34: '?',\n",
       " 35: '(',\n",
       " 36: ')',\n",
       " 37: '!',\n",
       " 38: ';',\n",
       " 39: ':',\n",
       " 40: '¨',\n",
       " 41: '-',\n",
       " 42: '1',\n",
       " 43: '6',\n",
       " 44: '9',\n",
       " 45: '5',\n",
       " 46: '8',\n",
       " 47: '\\x96',\n",
       " 48: '4',\n",
       " 49: '/',\n",
       " 50: '7',\n",
       " 51: '$',\n",
       " 52: '£',\n",
       " 53: '*',\n",
       " 54: '´',\n",
       " 55: '&',\n",
       " 56: '3',\n",
       " 57: '`',\n",
       " 58: 'é',\n",
       " 59: '=',\n",
       " 60: '%',\n",
       " 61: 'ê',\n",
       " 62: '[',\n",
       " 63: ']',\n",
       " 64: '\\x85',\n",
       " 65: '~',\n",
       " 66: '+',\n",
       " 67: '#',\n",
       " 68: 'è',\n",
       " 69: 'ó',\n",
       " 70: '\\x84',\n",
       " 71: '@',\n",
       " 72: '_',\n",
       " 73: '\\x97',\n",
       " 74: 'ı',\n",
       " 75: 'á',\n",
       " 76: 'ä',\n",
       " 77: '’',\n",
       " 78: '–',\n",
       " 79: '‘',\n",
       " 80: 'ï',\n",
       " 81: 'à',\n",
       " 82: '½',\n",
       " 83: '®',\n",
       " 84: 'â',\n",
       " 85: 'ç',\n",
       " 86: 'ö',\n",
       " 87: 'ù',\n",
       " 88: 'ü',\n",
       " 89: '^',\n",
       " 90: '<',\n",
       " 91: '>',\n",
       " 92: 'æ',\n",
       " 93: '¡',\n",
       " 94: '，',\n",
       " 95: '、',\n",
       " 96: '{',\n",
       " 97: '}',\n",
       " 98: 'ã',\n",
       " 99: '“',\n",
       " 100: '”',\n",
       " 101: 'ñ',\n",
       " 102: '\\x91',\n",
       " 103: '…',\n",
       " 104: 'ø',\n",
       " 105: '|',\n",
       " 106: '·',\n",
       " 107: 'ô'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train review model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SENTS_PER_DOC = 10\n",
      "\n",
      "MAX_WORDS_PER_SENT = 40\n",
      "\n",
      "MAX_CHARS_PER_WORD = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MAX_SENTS_PER_DOC = int(np.mean(sents_per_docs_lengths)) + 1\n",
    "MAX_WORDS_PER_SENT = int(np.mean(words_per_sents_lengths)) + 1\n",
    "MAX_CHARS_PER_WORD = int(np.mean(chars_per_words_lengths)) + 1\n",
    "'''\n",
    "MAX_SENTS_PER_DOC = 10\n",
    "MAX_WORDS_PER_SENT = 40\n",
    "MAX_CHARS_PER_WORD = 20\n",
    "print('MAX_SENTS_PER_DOC = ' + str(MAX_SENTS_PER_DOC) + '\\n')\n",
    "print('MAX_WORDS_PER_SENT = ' + str(MAX_WORDS_PER_SENT) + '\\n')\n",
    "print('MAX_CHARS_PER_WORD = ' + str(MAX_CHARS_PER_WORD) + '\\n')\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data, train_targets = vectorize_sentences_data(input_texts=train_texts, \n",
    "                                                               target_labels=list(data_train.sentiment), \n",
    "                                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                                               num_classes=NUM_CLASSES, \n",
    "                                                               char2int=char2int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data, _ = vectorize_sentences_data(input_texts=test_texts, \n",
    "                                               target_labels=None, \n",
    "                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                               num_classes=NUM_CLASSES, \n",
    "                                               char2int=char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 40, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 40, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, None, 108)         11664     \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection [(None, None, 1024), (Non 2543616   \n",
      "_________________________________________________________________\n",
      "lambda_40 (Lambda)           (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 2,555,280\n",
      "Trainable params: 2,543,616\n",
      "Non-trainable params: 11,664\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 40, 20)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 40, 1024)          2555280   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection [(None, 40, 512), (None,  2623488   \n",
      "_________________________________________________________________\n",
      "lambda_41 (Lambda)           (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 5,178,768\n",
      "Trainable params: 5,167,104\n",
      "Non-trainable params: 11,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "(None, 1, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 10, 40, 20)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 40, 20)       0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Model)                (None, 512)          5178768     lambda_42[0][0]                  \n",
      "                                                                 lambda_43[0][0]                  \n",
      "                                                                 lambda_44[0][0]                  \n",
      "                                                                 lambda_45[0][0]                  \n",
      "                                                                 lambda_46[0][0]                  \n",
      "                                                                 lambda_47[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 lambda_50[0][0]                  \n",
      "                                                                 lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 1, 512)       0           model_10[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 1, 512)       0           model_10[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 1, 512)       0           model_10[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 1, 512)       0           model_10[4][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_35 (Reshape)            (None, 1, 512)       0           model_10[5][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 1, 512)       0           model_10[6][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 1, 512)       0           model_10[7][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 1, 512)       0           model_10[8][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_39 (Reshape)            (None, 1, 512)       0           model_10[9][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)            (None, 1, 512)       0           model_10[10][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 10, 512)      0           reshape_31[0][0]                 \n",
      "                                                                 reshape_32[0][0]                 \n",
      "                                                                 reshape_33[0][0]                 \n",
      "                                                                 reshape_34[0][0]                 \n",
      "                                                                 reshape_35[0][0]                 \n",
      "                                                                 reshape_36[0][0]                 \n",
      "                                                                 reshape_37[0][0]                 \n",
      "                                                                 reshape_38[0][0]                 \n",
      "                                                                 reshape_39[0][0]                 \n",
      "                                                                 reshape_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) [(None, 10, 256), (N 656384      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 256)          0           bidirectional_9[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 5,835,152\n",
      "Trainable params: 5,823,488\n",
      "Non-trainable params: 11,664\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 10, 40, 20)        0         \n",
      "_________________________________________________________________\n",
      "model_11 (Model)             (None, 256)               5835152   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 5,835,666\n",
      "Trainable params: 5,824,002\n",
      "Non-trainable params: 11,664\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "char2word_latent_dim = 512\n",
    "word2sent_latent_dim = 256\n",
    "sent2doc_latent_dim = 128\n",
    "char_vocab_size = len(char2int)\n",
    "\n",
    "#MAX_SENTS_PER_DOC = 11\n",
    "#MAX_WORDS_PER_SENT = 24\n",
    "#MAX_CHARS_PER_WORD = 5\n",
    "#_, _, _, encoder_word_embedding_model = build_chars2word_model(num_encoder_tokens=char_vocab_size, latent_dim=chars2word_latent_dim)\n",
    "encoder_word_embedding_model = build_chars2word_model_simple_BiLSTM(num_encoder_tokens=char_vocab_size, latent_dim=char2word_latent_dim)\n",
    "print(encoder_word_embedding_model.summary())\n",
    "'''\n",
    "_, _, _, encoder_sentence_embedding_model = build_words2sent_model(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD,\n",
    "                                                                   latent_dim=words2sent_latent_dim)\n",
    "'''\n",
    "encoder_sentence_embedding_model = build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                                   latent_dim=word2sent_latent_dim)\n",
    "print(encoder_sentence_embedding_model.summary())\n",
    "\n",
    "encoder_document_embedding_model = build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                                                 max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                                 max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                 max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                 word2sent_latent_dim=word2sent_latent_dim,\n",
    "                                                 sent2doc_latent_dim=sent2doc_latent_dim)\n",
    "print(encoder_document_embedding_model.summary())\n",
    "model = build_hier_senti_model(encoder_document_embedding_model=encoder_document_embedding_model,\n",
    "                                max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                max_char_seq_len=MAX_CHARS_PER_WORD)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[20,2560,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArrayStack/TensorArrayGatherV3}} = TensorArrayGatherV3[_class=[\"loc:@train...yScatterV3\"], dtype=DT_FLOAT, element_shape=[?,512], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArray, model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArrayStack/range, model_3/model_2_9/time_distributed_1/bidirectional_1/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node model_3/model_2_8/time_distributed_1/bidirectional_1/while_1/LoopCond/_979}} = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_55276...1/LoopCond\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmodel_3/model_2_8/time_distributed_1/bidirectional_1/while_1/TensorArrayReadV3_1/_234)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ff8cedd647e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,2560,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArrayStack/TensorArrayGatherV3}} = TensorArrayGatherV3[_class=[\"loc:@train...yScatterV3\"], dtype=DT_FLOAT, element_shape=[?,512], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArray, model_3/model_2_9/time_distributed_1/bidirectional_1/TensorArrayStack/range, model_3/model_2_9/time_distributed_1/bidirectional_1/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node model_3/model_2_8/time_distributed_1/bidirectional_1/while_1/LoopCond/_979}} = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_55276...1/LoopCond\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopmodel_3/model_2_8/time_distributed_1/bidirectional_1/while_1/TensorArrayReadV3_1/_234)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_hier_senti_model-{}-{}.hdf5\".format(MAX_SENTS_PER_DOC,MAX_WORDS_PER_SENT,MAX_CHARS_PER_WORD) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "model.fit(train_input_data, train_targets,\n",
    "          #validation_data=(test_input_data, test_targets)\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rev in enumerate(test_texts):\n",
    "    print(rev)\n",
    "    sentiment = model.predict(test_input_data[i])\n",
    "    print('Sentiment: ' + str(sentiment))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
