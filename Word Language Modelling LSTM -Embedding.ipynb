{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtext = open('./dat/wonderland.txt','r').read().split('\\n')\n",
    "rawtext = ' '.join(rawtext)\n",
    "rawtext = [word.strip(string.punctuation) for word in rawtext.split()]\n",
    "rawtext = ' '.join(rawtext)\n",
    "rawtext = rawtext.replace('-', ' ')\n",
    "rawtext = ' '.join(rawtext.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab: 3064\n"
     ]
    }
   ],
   "source": [
    "all_words = rawtext.split()\n",
    "unique_words = sorted(list(set(all_words)))\n",
    "n_vocab = len(unique_words) + 1\n",
    "print(\"Total Vocab:\", n_vocab)\n",
    "word_to_int = dict((w, i) for i, w in enumerate(unique_words))\n",
    "int_to_word = dict((i, w) for i, w in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26694\n"
     ]
    }
   ],
   "source": [
    "raw_text = rawtext.split()\n",
    "n_words = len(raw_text)\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns: 26692\n"
     ]
    }
   ],
   "source": [
    "seq_length = 2\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_words - seq_length):\n",
    "    seq_in  = raw_text[i: i+seq_length]\n",
    "    seq_out = raw_text[i+seq_length]\n",
    "    dataX.append([word_to_int[word] for word in seq_in])\n",
    "    dataY.append(word_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print('Total patterns:', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dataX to size of [samples, time steps, features] and scale it to 0-1\n",
    "# Represent dataY as one hot encoding\n",
    "X_train = np.reshape(dataX, (n_patterns, seq_length))#/float(n_vocab)\n",
    "Y_train = np_utils.to_categorical(dataY, num_classes=n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26692, 2)\n",
      "(26692, 3064)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 50)          153200    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 100)         60400     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3064)              309464    \n",
      "=================================================================\n",
      "Total params: 613,564\n",
      "Trainable params: 613,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_vocab, 50))# Use pre-trained GloVe\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"word-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26692/26692 [==============================] - 5s 194us/step - loss: 6.7020 - acc: 0.0567\n",
      "Epoch 2/10\n",
      " 1792/26692 [=>............................] - ETA: 2s - loss: 6.2474 - acc: 0.0586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_categorical_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26692/26692 [==============================] - 3s 95us/step - loss: 6.2256 - acc: 0.0572\n",
      "Epoch 3/10\n",
      "26692/26692 [==============================] - 2s 92us/step - loss: 6.1331 - acc: 0.0572\n",
      "Epoch 4/10\n",
      "26692/26692 [==============================] - 2s 83us/step - loss: 6.0516 - acc: 0.0573\n",
      "Epoch 5/10\n",
      "26692/26692 [==============================] - 3s 96us/step - loss: 5.8568 - acc: 0.0650\n",
      "Epoch 6/10\n",
      "26692/26692 [==============================] - 3s 98us/step - loss: 5.6558 - acc: 0.0698\n",
      "Epoch 7/10\n",
      "26692/26692 [==============================] - 3s 97us/step - loss: 5.5101 - acc: 0.0738\n",
      "Epoch 8/10\n",
      "26692/26692 [==============================] - 2s 88us/step - loss: 5.3884 - acc: 0.0786\n",
      "Epoch 9/10\n",
      "26692/26692 [==============================] - 2s 79us/step - loss: 5.2778 - acc: 0.0846\n",
      "Epoch 10/10\n",
      "26692/26692 [==============================] - 3s 97us/step - loss: 5.1822 - acc: 0.0934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f6dd931d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=10, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" on again \"\n",
      "\n",
      "Generated Sequence:\n",
      "the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was the Queen and was\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X_train)-1)\n",
    "pattern = dataX[start]\n",
    "result = []\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_word[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(2000):\n",
    "    x = np.reshape(pattern, (1, len(pattern)))\n",
    "    #x = x/float(n_vocab)\n",
    "    prediction = model.predict(x)\n",
    "    index = np.argmax(prediction)\n",
    "    result.append(int_to_word[index])\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nGenerated Sequence:\")\n",
    "print(' '.join(result))\n",
    "print(\"\\nDone.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
