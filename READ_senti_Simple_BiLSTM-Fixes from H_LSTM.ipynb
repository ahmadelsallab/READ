{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding, Lambda, Concatenate, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_alloc(device_id):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=device_id\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentences_data(input_texts, target_labels, max_sents_per_doc, max_words_per_sent, max_chars_per_word, \n",
    "                             num_classes, char2int):\n",
    "\n",
    "    \n",
    "    hier_input_data_lst = []\n",
    "    hier_target_data_lst = []\n",
    "\n",
    "    if(target_labels == None):\n",
    "        target_labels = np.zeros(len(input_texts), dtype='int32')\n",
    "    \n",
    "    for _, (input_text, target_label) in enumerate(zip(input_texts, target_labels)):\n",
    "        hier_input_data = np.zeros((max_sents_per_doc, \n",
    "                                    max_words_per_sent, \n",
    "                                    max_chars_per_word), dtype='float32')\n",
    "\n",
    "\n",
    "        hier_target_data = np.zeros(num_classes, dtype='float32')\n",
    "\n",
    "        #sents_lst = sent_tokenize(clean_str(BeautifulSoup(input_text).get_text())) # TODO: Move to clean str\n",
    "        sents_lst = sent_tokenize(input_text)\n",
    "        \n",
    "        \n",
    "        if len(sents_lst) > max_sents_per_doc:\n",
    "            continue\n",
    "        j=0\n",
    "        for _, sent in enumerate(sents_lst):\n",
    "                \n",
    "            words_lst = word_tokenize(input_text)\n",
    "            \n",
    "            if(len(words_lst) > max_words_per_sent):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            k=0\n",
    "            for _, word in enumerate(words_lst):\n",
    "                \n",
    "                \n",
    "                if(len(word) > max_chars_per_word):\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                l=0\n",
    "                for l, char in enumerate(word):\n",
    "                    # c0..cn\n",
    "                    if(char in char2int):\n",
    "                        hier_input_data[j, k, l] = char2int[char]\n",
    "                        try:\n",
    "                            hier_target_data[target_label] = 1\n",
    "                        except:\n",
    "                            print(target_label)\n",
    "                        l=l+1\n",
    "                k=k+1\n",
    "            j=j+1\n",
    "                            \n",
    "        hier_input_data_lst.append(hier_input_data)\n",
    "        hier_target_data_lst.append(hier_target_data)\n",
    "                \n",
    "    return np.array(hier_input_data_lst), np.array(hier_target_data_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars2word_model_simple_BiLSTM(num_encoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
    "    \n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, latent_dim,                                                       \n",
    "                            mask_zero=True)(encoder_inputs)    \n",
    "    '''\n",
    "    print(encoder_inputs.shape)\n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(encoder_inputs)     \n",
    "    '''\n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    print(encoder_inputs_.shape)\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    " \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_word_embedding_model = Model(input=encoder_inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len, \n",
    "                           latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "\n",
    "    inputs = Input(shape=(max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    #print(inputs.shape)\n",
    "    input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "    encoder_inputs_ = input_words   \n",
    "    #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "        \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_sentence_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_sentence_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                         max_sents_seq_len, \n",
    "                         max_words_seq_len, \n",
    "                         max_char_seq_len, \n",
    "                         word2sent_latent_dim,\n",
    "                         sent2doc_latent_dim):\n",
    "    \n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    \n",
    "    sents_states = []\n",
    "    \n",
    "    for s in range(max_sents_seq_len):\n",
    "        \n",
    "        encoder_words_inputs = Lambda(lambda x: x[:,s,:,:])(inputs)\n",
    "        #print(encoder_words_inputs.shape)\n",
    "        encoder_words_outputs = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        encoder_words_outputs = Reshape((1,word2sent_latent_dim*2))(encoder_words_outputs)\n",
    "        #_, h, c = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        '''\n",
    "        input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "        encoder_inputs_ = input_words   \n",
    "        #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "        encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "        encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "\n",
    "        encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #encoder_words_states = Concatenate()([h,c])\n",
    "        #print(encoder_chars_states)\n",
    "        #encoder_words_states = Reshape((1,word2sent_latent_dim*4))(encoder_words_states)\n",
    "        #print(encoder_words_outputs.shape)\n",
    "        sents_states.append(encoder_words_outputs)\n",
    "    print(sents_states[0]._keras_shape)\n",
    "    input_sents = Concatenate(axis=-2)(sents_states)\n",
    "    #print(input_sents.shape)\n",
    "    encoder_inputs_ = input_sents   \n",
    "    encoder = Bidirectional(LSTM(sent2doc_latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    \n",
    "    encoder_document_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "    '''\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    '''\n",
    "    #return model, encoder_document_embedding_model\n",
    "    return encoder_document_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hier_senti_model(encoder_document_embedding_model,\n",
    "                           max_sents_seq_len, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len):\n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    encoder_embedding_output = encoder_document_embedding_model(inputs)\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/labeledTrainData.tsv'\n",
    "data_train = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = data_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/testData.tsv'\n",
    "data_test = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = data_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        With all this stuff going down at the moment w...\n",
       "1        \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2        The film starts with a manager (Nicholas Bell)...\n",
       "3        It must be assumed that those who praised this...\n",
       "4        Superbly trashy and wondrously unpretentious 8...\n",
       "5        I dont know why people think this is such a ba...\n",
       "6        This movie could have been very good, but come...\n",
       "7        I watched this video at a friend's house. I'm ...\n",
       "8        A friend of mine bought this film for £1, and ...\n",
       "9        <br /><br />This movie is full of references. ...\n",
       "10       What happens when an army of wetbacks, towelhe...\n",
       "11       Although I generally do not like remakes belie...\n",
       "12       \\Mr. Harvey Lights a Candle\\\" is anchored by a...\n",
       "13       I had a feeling that after \\Submerged\\\", this ...\n",
       "14       note to George Litman, and others: the Mystery...\n",
       "15       Stephen King adaptation (scripted by King hims...\n",
       "16       `The Matrix' was an exciting summer blockbuste...\n",
       "17       Ulli Lommel's 1980 film 'The Boogey Man' is no...\n",
       "18       This movie is one among the very few Indian mo...\n",
       "19       Most people, especially young people, may not ...\n",
       "20       \\Soylent Green\\\" is one of the best and most d...\n",
       "21       Michael Stearns plays Mike, a sexually frustra...\n",
       "22       This happy-go-luck 1939 military swashbuckler,...\n",
       "23       I would love to have that two hours of my life...\n",
       "24       The script for this movie was probably found i...\n",
       "25       Looking for Quo Vadis at my local video store,...\n",
       "26       Note to all mad scientists everywhere: if you'...\n",
       "27       What the ........... is this ? This must, with...\n",
       "28       Intrigued by the synopsis (every gay video the...\n",
       "29       Would anyone really watch this RUBBISH if it d...\n",
       "                               ...                        \n",
       "24970    Red Rock West (1993)<br /><br />Nicolas Cage g...\n",
       "24971    what can i say?, ms Erika Eleniak is my favori...\n",
       "24972    The spoiler warning is for those people who wa...\n",
       "24973    What do you call a horror story without horror...\n",
       "24974    Though not a horror film in the traditional se...\n",
       "24975    This was what black society was like before th...\n",
       "24976    They probably should have called this movie Th...\n",
       "24977    Attractive Marjorie(Farrah Fawcett)lives in fe...\n",
       "24978    Vaguely reminiscent of great 1940's westerns, ...\n",
       "24979    I admit I had no idea what to expect before vi...\n",
       "24980    To me, the final scene, in which Harris respon...\n",
       "24981    This is by far the funniest short made by the ...\n",
       "24982    To be a Buster Keaton fan is to have your hear...\n",
       "24983    I was one of those \\few Americans\\\" that grew ...\n",
       "24984    Visually disjointed and full of itself, the di...\n",
       "24985    this movie had more holes than a piece of swis...\n",
       "24986    Last November, I had a chance to see this film...\n",
       "24987    First off, I'd like to make a correction on an...\n",
       "24988    While originally reluctant to jump on the band...\n",
       "24989    I heard about this movie when watching VH1's \\...\n",
       "24990    I've never been huge on IMAX films. They're co...\n",
       "24991    Steve McQueen has certainly a lot of loyal fan...\n",
       "24992    Sometimes you wonder how some people get fundi...\n",
       "24993    I am a student of film, and have been for seve...\n",
       "24994    Unimaginably stupid, redundant and humiliating...\n",
       "24995    It seems like more consideration has gone into...\n",
       "24996    I don't believe they made this film. Completel...\n",
       "24997    Guy is a loser. Can't get girls, needs to buil...\n",
       "24998    This 30 minute documentary Buñuel made in the ...\n",
       "24999    I saw this movie as a child and it broke my he...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = data_train.review  + data_test.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars_per_words_lengths = []\n",
    "words_per_sents_lengths = []\n",
    "sents_per_docs_lengths = []\n",
    "\n",
    "# Chars per word should be on all text\n",
    "\n",
    "for text in all_texts:\n",
    "    \n",
    "    sents = sent_tokenize(clean_str(BeautifulSoup(text).get_text()))\n",
    "    sents_per_docs_lengths.append(len(sents))\n",
    "    for sent in sents:       \n",
    "    \n",
    "        words = word_tokenize(text)\n",
    "        words_per_sents_lengths.append(len(words))\n",
    "        for word in words:\n",
    "            chars_per_words_lengths.append(len(word))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa43c089fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_s = plt.hist(sents_per_docs_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.207560000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.078223632261627"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3cc20ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_w = plt.hist(words_per_sents_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689.28778734295486"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3067"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.16663872920708"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3c47294e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_c = plt.hist(chars_per_words_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8747657059975036"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5450141543538503"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "all_texts = list(all_texts.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "train_texts = list(data_train.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n",
    "test_texts = list(data_test.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char vocab (all text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_to_int, int_to_vocab = build_chars_vocab(all_texts)\n",
    "#np.savez('vocab_char-{}'.format(max_sent_len), vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, max_sent_len=max_sent_len, min_sent_len=min_sent_len )\n",
    "char2int = vocab_to_int\n",
    "int2char = int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in all_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25000\n",
      "Number of unique input tokens: 162\n",
      "Number of unique output tokens: 162\n",
      "Max sequence length for inputs: 14299\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(all_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '!': 37,\n",
       " '#': 67,\n",
       " '$': 51,\n",
       " '%': 60,\n",
       " '&': 55,\n",
       " '(': 35,\n",
       " ')': 36,\n",
       " '*': 53,\n",
       " '+': 66,\n",
       " ',': 23,\n",
       " '-': 41,\n",
       " '.': 27,\n",
       " '/': 49,\n",
       " '0': 31,\n",
       " '1': 42,\n",
       " '2': 30,\n",
       " '3': 56,\n",
       " '4': 48,\n",
       " '5': 45,\n",
       " '6': 43,\n",
       " '7': 50,\n",
       " '8': 46,\n",
       " '9': 44,\n",
       " ':': 39,\n",
       " ';': 38,\n",
       " '<': 90,\n",
       " '=': 59,\n",
       " '>': 91,\n",
       " '?': 34,\n",
       " '@': 71,\n",
       " 'UNK': 0,\n",
       " '[': 62,\n",
       " ']': 63,\n",
       " '^': 89,\n",
       " '_': 72,\n",
       " '`': 57,\n",
       " 'a': 8,\n",
       " 'b': 28,\n",
       " 'c': 22,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 12,\n",
       " 'g': 13,\n",
       " 'h': 7,\n",
       " 'i': 5,\n",
       " 'j': 19,\n",
       " 'k': 26,\n",
       " 'l': 9,\n",
       " 'm': 18,\n",
       " 'n': 15,\n",
       " 'o': 14,\n",
       " 'p': 29,\n",
       " 'q': 33,\n",
       " 'r': 21,\n",
       " 's': 10,\n",
       " 't': 6,\n",
       " 'u': 11,\n",
       " 'v': 20,\n",
       " 'w': 4,\n",
       " 'x': 32,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " '{': 96,\n",
       " '|': 105,\n",
       " '}': 97,\n",
       " '~': 65,\n",
       " '\\x80': 123,\n",
       " '\\x84': 70,\n",
       " '\\x85': 64,\n",
       " '\\x8d': 134,\n",
       " '\\x8e': 155,\n",
       " '\\x91': 102,\n",
       " '\\x95': 125,\n",
       " '\\x96': 47,\n",
       " '\\x97': 73,\n",
       " '\\x9a': 159,\n",
       " '\\x9e': 156,\n",
       " '\\xa0': 148,\n",
       " '¡': 93,\n",
       " '¢': 133,\n",
       " '£': 52,\n",
       " '¤': 152,\n",
       " '¦': 118,\n",
       " '§': 153,\n",
       " '¨': 40,\n",
       " '©': 144,\n",
       " 'ª': 145,\n",
       " '«': 130,\n",
       " '\\xad': 150,\n",
       " '®': 83,\n",
       " '°': 146,\n",
       " '³': 149,\n",
       " '´': 54,\n",
       " '·': 106,\n",
       " 'º': 151,\n",
       " '»': 131,\n",
       " '½': 82,\n",
       " '¾': 122,\n",
       " '¿': 115,\n",
       " 'ß': 127,\n",
       " 'à': 81,\n",
       " 'á': 75,\n",
       " 'â': 84,\n",
       " 'ã': 98,\n",
       " 'ä': 76,\n",
       " 'å': 119,\n",
       " 'æ': 92,\n",
       " 'ç': 85,\n",
       " 'è': 68,\n",
       " 'é': 58,\n",
       " 'ê': 61,\n",
       " 'ë': 110,\n",
       " 'ì': 112,\n",
       " 'í': 113,\n",
       " 'î': 116,\n",
       " 'ï': 80,\n",
       " 'ð': 117,\n",
       " 'ñ': 101,\n",
       " 'ò': 114,\n",
       " 'ó': 69,\n",
       " 'ô': 107,\n",
       " 'õ': 120,\n",
       " 'ö': 86,\n",
       " 'ø': 104,\n",
       " 'ù': 87,\n",
       " 'ú': 132,\n",
       " 'û': 121,\n",
       " 'ü': 88,\n",
       " 'ý': 129,\n",
       " 'þ': 128,\n",
       " 'č': 154,\n",
       " 'ğ': 124,\n",
       " 'ı': 74,\n",
       " 'ō': 108,\n",
       " 'ř': 126,\n",
       " 'ż': 157,\n",
       " 'א': 137,\n",
       " 'ג': 136,\n",
       " 'ו': 142,\n",
       " 'י': 135,\n",
       " 'כ': 139,\n",
       " 'ל': 138,\n",
       " 'מ': 141,\n",
       " 'ן': 143,\n",
       " 'ר': 140,\n",
       " '–': 78,\n",
       " '‘': 79,\n",
       " '’': 77,\n",
       " '“': 99,\n",
       " '”': 100,\n",
       " '…': 103,\n",
       " '″': 111,\n",
       " '₤': 109,\n",
       " '▼': 158,\n",
       " '★': 160,\n",
       " '、': 95,\n",
       " '\\uf04a': 161,\n",
       " '\\uf0b7': 147,\n",
       " '，': 94}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'w',\n",
       " 5: 'i',\n",
       " 6: 't',\n",
       " 7: 'h',\n",
       " 8: 'a',\n",
       " 9: 'l',\n",
       " 10: 's',\n",
       " 11: 'u',\n",
       " 12: 'f',\n",
       " 13: 'g',\n",
       " 14: 'o',\n",
       " 15: 'n',\n",
       " 16: 'd',\n",
       " 17: 'e',\n",
       " 18: 'm',\n",
       " 19: 'j',\n",
       " 20: 'v',\n",
       " 21: 'r',\n",
       " 22: 'c',\n",
       " 23: ',',\n",
       " 24: 'y',\n",
       " 25: 'z',\n",
       " 26: 'k',\n",
       " 27: '.',\n",
       " 28: 'b',\n",
       " 29: 'p',\n",
       " 30: '2',\n",
       " 31: '0',\n",
       " 32: 'x',\n",
       " 33: 'q',\n",
       " 34: '?',\n",
       " 35: '(',\n",
       " 36: ')',\n",
       " 37: '!',\n",
       " 38: ';',\n",
       " 39: ':',\n",
       " 40: '¨',\n",
       " 41: '-',\n",
       " 42: '1',\n",
       " 43: '6',\n",
       " 44: '9',\n",
       " 45: '5',\n",
       " 46: '8',\n",
       " 47: '\\x96',\n",
       " 48: '4',\n",
       " 49: '/',\n",
       " 50: '7',\n",
       " 51: '$',\n",
       " 52: '£',\n",
       " 53: '*',\n",
       " 54: '´',\n",
       " 55: '&',\n",
       " 56: '3',\n",
       " 57: '`',\n",
       " 58: 'é',\n",
       " 59: '=',\n",
       " 60: '%',\n",
       " 61: 'ê',\n",
       " 62: '[',\n",
       " 63: ']',\n",
       " 64: '\\x85',\n",
       " 65: '~',\n",
       " 66: '+',\n",
       " 67: '#',\n",
       " 68: 'è',\n",
       " 69: 'ó',\n",
       " 70: '\\x84',\n",
       " 71: '@',\n",
       " 72: '_',\n",
       " 73: '\\x97',\n",
       " 74: 'ı',\n",
       " 75: 'á',\n",
       " 76: 'ä',\n",
       " 77: '’',\n",
       " 78: '–',\n",
       " 79: '‘',\n",
       " 80: 'ï',\n",
       " 81: 'à',\n",
       " 82: '½',\n",
       " 83: '®',\n",
       " 84: 'â',\n",
       " 85: 'ç',\n",
       " 86: 'ö',\n",
       " 87: 'ù',\n",
       " 88: 'ü',\n",
       " 89: '^',\n",
       " 90: '<',\n",
       " 91: '>',\n",
       " 92: 'æ',\n",
       " 93: '¡',\n",
       " 94: '，',\n",
       " 95: '、',\n",
       " 96: '{',\n",
       " 97: '}',\n",
       " 98: 'ã',\n",
       " 99: '“',\n",
       " 100: '”',\n",
       " 101: 'ñ',\n",
       " 102: '\\x91',\n",
       " 103: '…',\n",
       " 104: 'ø',\n",
       " 105: '|',\n",
       " 106: '·',\n",
       " 107: 'ô',\n",
       " 108: 'ō',\n",
       " 109: '₤',\n",
       " 110: 'ë',\n",
       " 111: '″',\n",
       " 112: 'ì',\n",
       " 113: 'í',\n",
       " 114: 'ò',\n",
       " 115: '¿',\n",
       " 116: 'î',\n",
       " 117: 'ð',\n",
       " 118: '¦',\n",
       " 119: 'å',\n",
       " 120: 'õ',\n",
       " 121: 'û',\n",
       " 122: '¾',\n",
       " 123: '\\x80',\n",
       " 124: 'ğ',\n",
       " 125: '\\x95',\n",
       " 126: 'ř',\n",
       " 127: 'ß',\n",
       " 128: 'þ',\n",
       " 129: 'ý',\n",
       " 130: '«',\n",
       " 131: '»',\n",
       " 132: 'ú',\n",
       " 133: '¢',\n",
       " 134: '\\x8d',\n",
       " 135: 'י',\n",
       " 136: 'ג',\n",
       " 137: 'א',\n",
       " 138: 'ל',\n",
       " 139: 'כ',\n",
       " 140: 'ר',\n",
       " 141: 'מ',\n",
       " 142: 'ו',\n",
       " 143: 'ן',\n",
       " 144: '©',\n",
       " 145: 'ª',\n",
       " 146: '°',\n",
       " 147: '\\uf0b7',\n",
       " 148: '\\xa0',\n",
       " 149: '³',\n",
       " 150: '\\xad',\n",
       " 151: 'º',\n",
       " 152: '¤',\n",
       " 153: '§',\n",
       " 154: 'č',\n",
       " 155: '\\x8e',\n",
       " 156: '\\x9e',\n",
       " 157: 'ż',\n",
       " 158: '▼',\n",
       " 159: '\\x9a',\n",
       " 160: '★',\n",
       " 161: '\\uf04a'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train review model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SENTS_PER_DOC = 10\n",
      "\n",
      "MAX_WORDS_PER_SENT = 40\n",
      "\n",
      "MAX_CHARS_PER_WORD = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MAX_SENTS_PER_DOC = int(np.mean(sents_per_docs_lengths)) + 1\n",
    "MAX_WORDS_PER_SENT = int(np.mean(words_per_sents_lengths)) + 1\n",
    "MAX_CHARS_PER_WORD = int(np.mean(chars_per_words_lengths)) + 1\n",
    "'''\n",
    "MAX_SENTS_PER_DOC = 10\n",
    "MAX_WORDS_PER_SENT = 40\n",
    "MAX_CHARS_PER_WORD = 20\n",
    "print('MAX_SENTS_PER_DOC = ' + str(MAX_SENTS_PER_DOC) + '\\n')\n",
    "print('MAX_WORDS_PER_SENT = ' + str(MAX_WORDS_PER_SENT) + '\\n')\n",
    "print('MAX_CHARS_PER_WORD = ' + str(MAX_CHARS_PER_WORD) + '\\n')\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data, train_targets = vectorize_sentences_data(input_texts=train_texts, \n",
    "                                                               target_labels=list(data_train.sentiment), \n",
    "                                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                                               num_classes=NUM_CLASSES, \n",
    "                                                               char2int=char2int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data, _ = vectorize_sentences_data(input_texts=test_texts, \n",
    "                                               target_labels=None, \n",
    "                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                               num_classes=NUM_CLASSES, \n",
    "                                               char2int=char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15600, 10, 40, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15600"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15600, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15908, 10, 40, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          8100      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, None, 100), (None 40400     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 48,500\n",
      "Trainable params: 48,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 40, 20)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 100)           48500     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection [(None, 40, 256), (None,  234496    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 282,996\n",
      "Trainable params: 282,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(None, 1, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10, 40, 20)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 40, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 256)          282996      lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 256)       0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 256)       0           model_2[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 256)       0           model_2[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 256)       0           model_2[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 256)       0           model_2[6][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 256)       0           model_2[7][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 256)       0           model_2[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 256)       0           model_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 256)       0           model_2[10][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 256)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 10, 256), (N 394240      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 256)          0           bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 677,236\n",
      "Trainable params: 677,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10, 40, 20)        0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 256)               677236    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 677,750\n",
      "Trainable params: 677,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "char2word_latent_dim = 50\n",
    "word2sent_latent_dim = 128\n",
    "sent2doc_latent_dim = 128\n",
    "char_vocab_size = len(char2int)\n",
    "\n",
    "#MAX_SENTS_PER_DOC = 11\n",
    "#MAX_WORDS_PER_SENT = 24\n",
    "#MAX_CHARS_PER_WORD = 5\n",
    "#_, _, _, encoder_word_embedding_model = build_chars2word_model(num_encoder_tokens=char_vocab_size, latent_dim=chars2word_latent_dim)\n",
    "encoder_word_embedding_model = build_chars2word_model_simple_BiLSTM(num_encoder_tokens=char_vocab_size, latent_dim=char2word_latent_dim)\n",
    "print(encoder_word_embedding_model.summary())\n",
    "'''\n",
    "_, _, _, encoder_sentence_embedding_model = build_words2sent_model(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD,\n",
    "                                                                   latent_dim=words2sent_latent_dim)\n",
    "'''\n",
    "encoder_sentence_embedding_model = build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                                   latent_dim=word2sent_latent_dim)\n",
    "print(encoder_sentence_embedding_model.summary())\n",
    "\n",
    "encoder_document_embedding_model = build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                                                 max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                                 max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                 max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                 word2sent_latent_dim=word2sent_latent_dim,\n",
    "                                                 sent2doc_latent_dim=sent2doc_latent_dim)\n",
    "print(encoder_document_embedding_model.summary())\n",
    "model = build_hier_senti_model(encoder_document_embedding_model=encoder_document_embedding_model,\n",
    "                                max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                max_char_seq_len=MAX_CHARS_PER_WORD)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12480 samples, validate on 3120 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_hier_senti_model-{}-{}.hdf5\".format(MAX_SENTS_PER_DOC,MAX_WORDS_PER_SENT,MAX_CHARS_PER_WORD) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "model.fit(train_input_data, train_targets,\n",
    "          #validation_data=(test_input_data, test_targets)\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rev in enumerate(test_texts):\n",
    "    print(rev)\n",
    "    sentiment = model.predict(np.expand_dims(test_input_data[i], 0))\n",
    "    print('Sentiment: ' + str(sentiment))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
