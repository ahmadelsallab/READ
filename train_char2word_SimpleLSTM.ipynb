{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding, Lambda, Concatenate, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import spell\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial noisy spelling mistakes\n",
    "def noise_maker(sentence, threshold):\n",
    "    '''Relocate, remove, or add characters to create spelling mistakes'''\n",
    "    letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "           'n','o','p','q','r','s','t','u','v','w','x','y','z',]\n",
    "    noisy_sentence = []\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        random = np.random.uniform(0, 1, 1)\n",
    "        # Most characters will be correct since the threshold value is high\n",
    "        if random < threshold:\n",
    "            noisy_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_random = np.random.uniform(0, 1, 1)\n",
    "            # ~33% chance characters will swap locations\n",
    "            if new_random > 0.67:\n",
    "                if i == (len(sentence) - 1):\n",
    "                    # If last character in sentence, it will not be typed\n",
    "                    continue\n",
    "                else:\n",
    "                    # if any other character, swap order with following character\n",
    "                    noisy_sentence.append(sentence[i + 1])\n",
    "                    noisy_sentence.append(sentence[i])\n",
    "                    i += 1\n",
    "            # ~33% chance an extra lower case letter will be added to the sentence\n",
    "            elif new_random < 0.33:\n",
    "                random_letter = np.random.choice(letters, 1)[0]\n",
    "                noisy_sentence.append(random_letter)\n",
    "                noisy_sentence.append(sentence[i])\n",
    "            # ~33% chance a character will not be typed\n",
    "            else:\n",
    "                pass\n",
    "        i += 1\n",
    "\n",
    "    return ''.join(noisy_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name, encoding='utf8'):\n",
    "        if cnt < num_samples :\n",
    "            #print(row)\n",
    "            sents = row.split(delimiter)\n",
    "            if (len(sents) < 2):\n",
    "                continue             \n",
    "            input_text = sents[prediction_index]\n",
    "            \n",
    "            target_text = '\\t' + sents[gt_index].strip() + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[gt_index])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_noise(file_name, num_samples, noise_threshold, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT>. The GT is just a noisy version of TXT. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    while cnt < num_samples :\n",
    "        for row in open(file_name, encoding='utf8'):\n",
    "        #for row in open(file_name):\n",
    "            if cnt < num_samples :\n",
    "                sents = row.split(\"\\t\")\n",
    "                if (len(sents) < 2):\n",
    "                    continue                 \n",
    "                input_text = noise_maker(sents[1], noise_threshold)\n",
    "                input_text = input_text[:-1]\n",
    "\n",
    "                target_text = '\\t' + sents[1].strip() + '\\n'            \n",
    "                if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                    cnt += 1\n",
    "                    input_texts.append(input_text)\n",
    "                    target_texts.append(target_text)\n",
    "                    gt_texts.append(target_text[1:-1])\n",
    "                    \n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_words_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:       \n",
    "        for word in word_tokenize(sentence):\n",
    "            word = process_word(word)\n",
    "            if word not in vocab_to_int:\n",
    "                vocab_to_int[word] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to word'''\n",
    "    int_to_vocab = {}\n",
    "    for word, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = word\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_char_data(input_texts, target_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "    decoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length),\n",
    "        dtype='float32')\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_encoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t] = vocab_to_int[char]\n",
    "        for t, char in enumerate(target_text):\n",
    "            # c0'..cm'\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t] = vocab_to_int[char]\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, vocab_to_int[char]] = 1.\n",
    "                \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_hier_data(input_texts, target_texts, max_words_seq_length, max_chars_seq_length, num_char_tokens, num_word_tokens, word2int, char2int):\n",
    "\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    # \n",
    "    encoder_char_input_data_lst = []\n",
    "    \n",
    "    decoder_word_input_data_lst = []\n",
    "    \n",
    "    decoder_word_target_data_lst = []\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        encoder_char_input_data = np.zeros((max_words_seq_length, max_chars_seq_length), dtype='float32')\n",
    "\n",
    "        decoder_word_input_data = np.zeros(max_words_seq_length, dtype='float32')\n",
    "\n",
    "        decoder_word_target_data = np.zeros((max_words_seq_length, num_word_tokens), dtype='float32')\n",
    "        words_lst = word_tokenize(input_text)\n",
    "        \n",
    "        if(len(words_lst) > max_words_seq_length):\n",
    "            continue\n",
    "        for j, word in enumerate(words_lst):\n",
    "            if(len(word) > max_chars_seq_length):\n",
    "                continue\n",
    "            for k, char in enumerate(word):\n",
    "                # c0..cn\n",
    "                if(char in char2int):\n",
    "                    encoder_char_input_data[j, k] = char2int[char]\n",
    "                    \n",
    "        words_lst = word_tokenize(target_text)# word_tokenize removes the \\t and \\n, we need them to start and end a sequence\n",
    "        words_lst.insert(0, '\\t')\n",
    "        words_lst.append('\\n')        \n",
    "        if(len(words_lst) > max_words_seq_length):\n",
    "            continue                \n",
    "        for j, word in enumerate(words_lst):\n",
    "            #processed_word = process_word(word)\n",
    "            processed_word = word\n",
    "            if not processed_word in word2int:\n",
    "                continue\n",
    "            # c0'..cm'\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_word_input_data[j] = word2int[processed_word]\n",
    "            if j > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_word_target_data[j - 1, word2int[processed_word]] = 1.\n",
    "                \n",
    "        encoder_char_input_data_lst.append(encoder_char_input_data)\n",
    "    \n",
    "        decoder_word_input_data_lst.append(decoder_word_input_data)\n",
    "    \n",
    "        decoder_word_target_data_lst.append(decoder_word_target_data)\n",
    "        \n",
    "    return np.array(encoder_char_input_data_lst), np.array(decoder_word_input_data_lst), np.array(decoder_word_target_data_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_gt_sequence(input_seq, int_to_vocab):\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    for i in range(input_seq.shape[1]):\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = input_seq[0][i]\n",
    "        sampled_word = int_to_vocab[sampled_token_index]\n",
    "        decoded_sentence += sampled_word + ' '\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, max_words_seq_len))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$']\n",
    "    i = 0\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "       \n",
    "        \n",
    "        #orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(word_tokenize(decoded_sentence)) > max_words_seq_len):\n",
    "            stop_condition = True\n",
    "            sampled_char = ''\n",
    "\n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        '''\n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        '''\n",
    "        decoded_sentence += sampled_char + ' '\n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        #target_seq = np.zeros((1, max_words_seq_len))\n",
    "        if i < max_words_seq_len:\n",
    "            target_seq[0, i] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        i += 1\n",
    "        #if i > 48:\n",
    "        #    i = 0\n",
    "        \n",
    "\n",
    "    attention_density = np.array(attention_density)\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_char_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "    i = 0\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$']\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            sampled_char = ''\n",
    "\n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        \n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        i += 1\n",
    "        if(i > 48):\n",
    "            i = 0\n",
    "    attention_density = np.array(attention_density)\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_char_model(num_encoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(encoder_inputs)    \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]# Bi GRU, LSTM, BHi LSTM\n",
    "    #print(encoder_states)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(decoder_inputs)    \n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)# Bi LSTM\n",
    "    \n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs_, initial_state=encoder_states)\n",
    "\n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    #print(decoder_outputs)\n",
    "    #print(encoder_outputs)\n",
    "    att_dot = Dot(axes=[2, 2])\n",
    "    attention = att_dot([decoder_outputs, encoder_outputs])\n",
    "    att_activation = Activation('softmax', name='attention')\n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    context_dot = Dot(axes=[2,1])\n",
    "    context = context_dot([attention, encoder_outputs])\n",
    "    #print('context', context)\n",
    "    att_context_concat = Concatenate()\n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "\n",
    "    decoder_dense = Dense(num_encoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    #model = Model(decoder_inputs, decoder_outputs)\n",
    "    #print('encoder-decoder  model:')\n",
    "    print(model.summary()) \n",
    "    \n",
    "    #print(encoder_inputs)\n",
    "    #print(encoder_outputs)\n",
    "    #print(encoder_states)\n",
    "    #encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
    "    encoder_model = Model(input=encoder_inputs, output=[encoder_outputs] + encoder_states)\n",
    "    print(encoder_outputs.shape)\n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_word_embedding_model = Model(input=encoder_inputs, output=encoder_embedding_output)\n",
    "\n",
    "    #decoder_state_input_h = Input(shape=(latent_dim,))# LSTM\n",
    "    #decoder_state_input_c = Input(shape=(latent_dim,))# LSTM\n",
    "    decoder_encoder_inputs = Input(shape=(None, latent_dim*2,))\n",
    "    decoder_state_input_h = Input(shape=(latent_dim*2,))# Bi LSTM\n",
    "    decoder_state_input_c = Input(shape=(latent_dim*2,)) # Bi LSTM\n",
    "    #decoder_state_input = Input(shape=(latent_dim*2,)) # Bi GRU\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    #decoder_states_inputs = [decoder_state_input] # Bi GRU\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_, initial_state=decoder_states_inputs)\n",
    "\n",
    "    #decoder_outputs, state = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    \n",
    "    attention = att_dot([decoder_outputs, decoder_encoder_inputs])\n",
    "    \n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    \n",
    "    context = context_dot([attention, decoder_encoder_inputs])\n",
    "    #print('context', context)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "    \n",
    "    #decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs, decoder_encoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs, attention] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model, encoder_word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hier_model(encoder_word_embedding_model, max_words_seq_len, max_char_seq_len, num_word_tokens, num_char_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "\n",
    "    inputs = Input(shape=(max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    decoder_inputs_words = Input(shape=(max_words_seq_len,), dtype='float32')\n",
    "    words_states = []\n",
    "    '''\n",
    "    for w in range(max_words_seq_len):\n",
    "        \n",
    "        encoder_char_inputs = Lambda(lambda x: x[:,w,:])(inputs)\n",
    "        _, h, c = encoder_char_model(encoder_char_inputs)\n",
    "        encoder_chars_states = Concatenate()([h,c])\n",
    "        #print(encoder_chars_states)\n",
    "        encoder_chars_states = Reshape((1,latent_dim*4))(encoder_chars_states)\n",
    "        words_states.append(encoder_chars_states)\n",
    "    \n",
    "    input_words = Concatenate(axis=-2)(words_states)\n",
    "\n",
    "    '''\n",
    "    #input_words = TimeDistributed(Dense(10))(inputs)\n",
    "\n",
    "    input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "    encoder_inputs_ = input_words   \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]# Bi GRU, LSTM, BHi LSTM\n",
    "    \n",
    "    decoder_inputs = decoder_inputs_words\n",
    "    decoder_inputs_ = Embedding(num_word_tokens, latent_dim*4,                           \n",
    "                            #weights=[np.eye(num_word_tokens)],\n",
    "                            mask_zero=True, trainable=True)(decoder_inputs)    \n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)# Bi LSTM\n",
    "    \n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs_, initial_state=encoder_states)\n",
    "\n",
    "    att_dot = Dot(axes=[2, 2])\n",
    "    attention = att_dot([decoder_outputs, encoder_outputs])\n",
    "    att_activation = Activation('softmax')\n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    context_dot = Dot(axes=[2,1])\n",
    "    context = context_dot([attention, encoder_outputs])\n",
    "    #print('context', context)\n",
    "    att_context_concat = Concatenate()\n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "\n",
    "    decoder_dense = Dense(num_word_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([inputs, decoder_inputs_words], decoder_outputs)\n",
    "    #model = Model(decoder_inputs, decoder_outputs)\n",
    "    print('encoder-decoder  model:')\n",
    "    print(model.summary()) \n",
    "    \n",
    "    #encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
    "    encoder_model = Model(input=inputs, output=[encoder_outputs] + encoder_states)\n",
    "\n",
    "    #decoder_state_input_h = Input(shape=(latent_dim,))# LSTM\n",
    "    #decoder_state_input_c = Input(shape=(latent_dim,))# LSTM\n",
    "    decoder_encoder_inputs = Input(shape=(max_words_seq_len, latent_dim*2,))\n",
    "    decoder_state_input_h = Input(shape=(latent_dim*2,))# Bi LSTM\n",
    "    decoder_state_input_c = Input(shape=(latent_dim*2,)) # Bi LSTM\n",
    "    #decoder_state_input = Input(shape=(latent_dim*2,)) # Bi GRU\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    #decoder_states_inputs = [decoder_state_input] # Bi GRU\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_, initial_state=decoder_states_inputs)\n",
    "\n",
    "    #decoder_outputs, state = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    \n",
    "    attention = att_dot([decoder_outputs, decoder_encoder_inputs])\n",
    "    \n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    \n",
    "    context = context_dot([attention, decoder_encoder_inputs])\n",
    "    #print('context', context)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "    \n",
    "    #decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs_words, decoder_encoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs, attention] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, vocab_to_int, int_to_vocab):\n",
    "\n",
    "    encoder_input_data = np.zeros((1, max_encoder_seq_length), dtype='float32')\n",
    "    \n",
    "    for t, char in enumerate(text):\n",
    "        # c0..cn\n",
    "        encoder_input_data[0, t] = vocab_to_int[char]\n",
    "\n",
    "    input_seq = encoder_input_data[0:1]\n",
    "\n",
    "    decoded_sentence, attention_density = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(28,12))\n",
    "    \n",
    "    ax = sns.heatmap(attention_density[:, : len(text) + 2],\n",
    "        xticklabels=[w for w in text],\n",
    "        yticklabels=[w for w in decoded_sentence])\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    # Try to correct the word from known dict\n",
    "    #word = spell(word)\n",
    "    # Option 1: Replace special chars and digits\n",
    "    #processed_word = re.sub(r'[\\\\\\/\\-\\—\\:\\[\\]\\,\\.\\\"\\;\\%\\~\\(\\)\\{\\}\\$\\#\\?\\●\\@\\+\\-\\*\\d]', r'', w.lower())\n",
    "    \n",
    "    # Option 2: skip all words with special chars or digits\n",
    "    if(len(re.findall(r'[\\\\\\/\\-\\—\\:\\[\\]\\,\\.\\\"\\;\\%\\~\\(\\)\\{\\}\\$\\#\\?\\●\\@\\+\\-\\*\\d]', word.lower())) == 0):\n",
    "        #processed_word = word.lower()\n",
    "        processed_word = word\n",
    "    else:\n",
    "        processed_word = 'UNK'\n",
    "\n",
    "    # Skip stop words\n",
    "    #stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]        \n",
    "    stop_words = []\n",
    "    if processed_word in stop_words:\n",
    "        processed_word = 'UNK'\n",
    "        \n",
    "    return processed_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'\n",
    "max_sent_len = 50\n",
    "min_sent_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ocr_data_2.txt\n",
      "field_class_21.txt\n",
      "field_class_22.txt\n",
      "field_class_23.txt\n",
      "field_class_24.txt\n",
      "field_class_25.txt\n",
      "field_class_26.txt\n",
      "field_class_27.txt\n",
      "field_class_28.txt\n",
      "field_class_29.txt\n",
      "field_class_30.txt\n",
      "field_class_31.txt\n",
      "field_class_32.txt\n",
      "field_class_33.txt\n",
      "field_class_34.txt\n",
      "NL-14622714.txt\n",
      "NL-14627449.txt\n",
      "NL-14628986.txt\n",
      "NL-14631911.txt\n",
      "NL-14640007.txt\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1000000\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "#files_list = ['all_ocr_data_2.txt', 'field_class_21.txt', 'field_class_32.txt', 'field_class_30.txt']\n",
    "files_list = ['all_ocr_data_2.txt', 'field_class_21.txt', 'field_class_22.txt', 'field_class_23.txt', 'field_class_24.txt', 'field_class_25.txt', 'field_class_26.txt', 'field_class_27.txt', 'field_class_28.txt', 'field_class_29.txt', 'field_class_30.txt', 'field_class_31.txt', 'field_class_32.txt', 'field_class_33.txt', 'field_class_34.txt', 'NL-14622714.txt', 'NL-14627449.txt', 'NL-14628986.txt', 'NL-14631911.txt', 'NL-14640007.txt']\n",
    "#desired_file_sizes = [num_samples, num_samples, num_samples, num_samples]\n",
    "desired_file_sizes = []\n",
    "for i in range(len(files_list)):\n",
    "    desired_file_sizes.append(num_samples)\n",
    "noise_threshold = 0.9\n",
    "\n",
    "for file_name, num_file_samples in zip(files_list, desired_file_sizes):\n",
    "    print(file_name)\n",
    "    tess_correction_data = os.path.join(data_path, file_name)\n",
    "    input_texts_OCR, target_texts_OCR, gt_OCR = load_data_with_gt(tess_correction_data, num_file_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0)\n",
    "\n",
    "    input_texts += input_texts_OCR\n",
    "    target_texts += target_texts_OCR\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9150"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9150\n",
      "Claim Type: VB Accident - Accidental Injury \n",
      " \tClaim Type: VB Accident - Accidental Injury\n",
      "\n",
      "Pol inyhold elm-Chm er [11 form arlon \n",
      " \tPolicyholder/Owner Information\n",
      "\n",
      "First Name: \n",
      " \tFirst Name:\n",
      "\n",
      "Middle Nameﬂnitial: \n",
      " \tMiddle Name/Initial:\n",
      "\n",
      "Last Name: \n",
      " \tLast Name:\n",
      "\n",
      "Social S ecurity Number: \n",
      " \tSocial Security Number:\n",
      "\n",
      "Birth Date: \n",
      " \tBirth Date:\n",
      "\n",
      "Gender: \n",
      " \tGender:\n",
      "\n",
      "Language Preference: \n",
      " \tLanguage Preference:\n",
      "\n",
      "Address Line 1: \n",
      " \tAddress Line 1:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars_per_words_lengths = []\n",
    "words_per_sents_lengths = []\n",
    "\n",
    "# Chars per word should be on all text\n",
    "for text in (input_texts_OCR+target_texts_OCR):\n",
    "    words = word_tokenize(text)\n",
    "    #words_per_sents_lengths.append(len(words))\n",
    "    for word in words:\n",
    "        chars_per_words_lengths.append(len(word))\n",
    "\n",
    "# Words in sent should be on target only        \n",
    "for text in target_texts_OCR:\n",
    "    words = word_tokenize(text)\n",
    "    words_per_sents_lengths.append(len(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAC29JREFUeJzt3X+o3fddx/Hny9yW/ULamtsSk+KtELoWYauEEi2ItBtWNpb8sUKHliCR/DNnp4OZ7R8R/KMD2eofIoS2LmBpV7JCSjvUkrUMQaI3befaxZFaZxcbmzu2uukfzri3f9yvGGJuz7n3nh/JO88HlHO+3/M5nPchyTPffM/53qaqkCRd/n5i3gNIkibDoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJamJhli+2devWWlpamuVLStJl78SJE9+tqsVR62Ya9KWlJZaXl2f5kpJ02Uvyz+Os85SLJDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQR1g6+My8R5CksRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGPRLmBc1SVoPgy5JTRh0SWrCoEtSEwZdkpow6JLUxNhBT7IlyYtJnh62b0pyPMmpJF9KcvX0xpQkjbKeI/T7gZPnbX8O+EJV7QS+D+yf5GCSpPUZK+hJdgAfAh4atgPcCRwZlhwG9k5jQEnSeMY9Qn8Q+DTw42H7p4C3qurcsH0a2D7h2SRJ6zAy6Ek+DJytqhPn777I0lrj+QeSLCdZXllZ2eCYkqRRxjlCvwP4SJJvA4+zeqrlQeCaJAvDmh3AGxd7clUdqqpdVbVrcXFxAiNLki5mZNCr6jNVtaOqloB7ga9W1a8BzwEfHZbtA45ObUpJ0kib+R767wG/m+RVVs+pPzyZkSRJG7Ewesn/qarngeeH+68Bt09+JEnSRnilqCQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhOXTdCXDj4z7xEk6ZJ22QRdkvT2DLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOgSsHTwmXmPIG3ayKAneUeSv03y9SSvJPmDYf9NSY4nOZXkS0munv64kqS1jHOE/p/AnVX1PuD9wN1JdgOfA75QVTuB7wP7pzemJGmUkUGvVf8+bF41/FfAncCRYf9hYO9UJpQkjWWsc+hJtiR5CTgLPAv8I/BWVZ0blpwGtk9nREnSOMYKelX9d1W9H9gB3A7ccrFlF3tukgNJlpMsr6ysbHxSSdLbWte3XKrqLeB5YDdwTZKF4aEdwBtrPOdQVe2qql2Li4ubmVWS9DbG+ZbLYpJrhvvvBD4AnASeAz46LNsHHJ3WkJKk0RZGL2EbcDjJFlb/Aniiqp5O8k3g8SR/CLwIPDzFOSVJI4wMelX9PXDbRfa/xur5dEnSJcArRSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJg67/x/8dm3R5MuiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJkUFPcmOS55KcTPJKkvuH/dcleTbJqeH22umPK0layzhH6OeAT1XVLcBu4ONJbgUOAseqaidwbNiWJM3JyKBX1ZmqemG4/0PgJLAd2AMcHpYdBvZOa0hJ0mjrOoeeZAm4DTgO3FBVZ2A1+sD1kx5OkjS+sYOe5D3Al4FPVtUP1vG8A0mWkyyvrKxsZEZJ0hjGCnqSq1iN+aNV9eSw+80k24bHtwFnL/bcqjpUVbuqatfi4uIkZpYkXcQ433IJ8DBwsqo+f95DTwH7hvv7gKOTH0+SNK6FMdbcAdwHfCPJS8O+zwIPAE8k2Q+8DtwznRElSeMYGfSq+msgazx812THkSRtlFeKSlITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJkUFP8kiSs0lePm/fdUmeTXJquL12umNKkkYZ5wj9i8DdF+w7CByrqp3AsWFbkjRHI4NeVV8DvnfB7j3A4eH+YWDvhOeSJK3TRs+h31BVZwCG2+snN5IkaSOm/qFokgNJlpMsr6ysTPvlJOmKtdGgv5lkG8Bwe3athVV1qKp2VdWuxcXFDb6cJGmUjQb9KWDfcH8fcHQy40iSNmqcry0+BvwNcHOS00n2Aw8AH0xyCvjgsC1JmqOFUQuq6mNrPHTXhGeRJG2CV4pKUhMGXZKaMOiS1IRBl6QmDLp0hVo6+My8R9CEGXRJasKgS1ITBl2SmjDoktSEQZd0xej+QbBBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTWwq6EnuTvKtJK8mOTipoSRJ67fhoCfZAvwJ8KvArcDHktw6qcEkSeuzmSP024FXq+q1qvoR8DiwZzJjSZLWazNB3w5857zt08M+SdIcpKo29sTkHuBXquo3h+37gNur6hMXrDsAHBg2bwa+tfFx52Ir8N15DzFjvucrg+/58vEzVbU4atHCJl7gNHDjeds7gDcuXFRVh4BDm3iduUqyXFW75j3HLPmerwy+5342c8rl74CdSW5KcjVwL/DUZMaSJK3Xho/Qq+pckt8C/hLYAjxSVa9MbDJJ0rps5pQLVfUV4CsTmuVSddmeLtoE3/OVwffczIY/FJUkXVq89F+SmjDoa0hyY5LnkpxM8kqS++c906wk2ZLkxSRPz3uWWUhyTZIjSf5h+PX+hXnPNG1Jfmf4ff1ykseSvGPeM01akkeSnE3y8nn7rkvybJJTw+2185xx0gz62s4Bn6qqW4DdwMevoB9tcD9wct5DzNAfA39RVe8F3kfz955kO/DbwK6q+jlWv9Rw73ynmoovAndfsO8gcKyqdgLHhu02DPoaqupMVb0w3P8hq3/I218Jm2QH8CHgoXnPMgtJfhL4JeBhgKr6UVW9Nd+pZmIBeGeSBeBdXOQakstdVX0N+N4Fu/cAh4f7h4G9Mx1qygz6GJIsAbcBx+c7yUw8CHwa+PG8B5mRnwVWgD8bTjM9lOTd8x5qmqrqX4A/Al4HzgD/VlV/Nd+pZuaGqjoDqwdtwPVznmeiDPoISd4DfBn4ZFX9YN7zTFOSDwNnq+rEvGeZoQXg54E/rarbgP+g2T/DLzScN94D3AT8NPDuJL8+36k0CQb9bSS5itWYP1pVT857nhm4A/hIkm+z+tMz70zy5/MdaepOA6er6n//9XWE1cB39gHgn6pqpar+C3gS+MU5zzQrbybZBjDcnp3zPBNl0NeQJKyeVz1ZVZ+f9zyzUFWfqaodVbXE6odkX62q1kduVfWvwHeS3Dzsugv45hxHmoXXgd1J3jX8Pr+L5h8En+cpYN9wfx9wdI6zTNymrhRt7g7gPuAbSV4a9n12uDpWvXwCeHT4mUSvAb8x53mmqqqOJzkCvMDqt7lepOEVlEkeA34Z2JrkNPD7wAPAE0n2s/oX2z3zm3DyvFJUkprwlIskNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCb+B4tgVyzoimICAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab820cae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_w = plt.hist(words_per_sents_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab81f3f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_c = plt.hist(chars_per_words_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char vocab (all text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = target_texts + input_texts\n",
    "vocab_to_int, int_to_vocab = build_chars_vocab(all_texts)\n",
    "np.savez('vocab_char-{}'.format(max_sent_len), vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, max_sent_len=max_sent_len, min_sent_len=min_sent_len )\n",
    "char2int = vocab_to_int\n",
    "int2char = int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 9150\n",
      "Number of unique input tokens: 126\n",
      "Number of unique output tokens: 126\n",
      "Max sequence length for inputs: 49\n",
      "Max sequence length for outputs: 49\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " '\\x0c': 120,\n",
       " ' ': 1,\n",
       " '!': 111,\n",
       " '\"': 95,\n",
       " '#': 67,\n",
       " '$': 79,\n",
       " '%': 85,\n",
       " '&': 73,\n",
       " \"'\": 83,\n",
       " '(': 61,\n",
       " ')': 62,\n",
       " '*': 77,\n",
       " '+': 76,\n",
       " ',': 69,\n",
       " '-': 21,\n",
       " '.': 54,\n",
       " '/': 29,\n",
       " '0': 63,\n",
       " '1': 43,\n",
       " '2': 53,\n",
       " '3': 52,\n",
       " '4': 66,\n",
       " '5': 74,\n",
       " '6': 65,\n",
       " '7': 70,\n",
       " '8': 58,\n",
       " '9': 72,\n",
       " ':': 13,\n",
       " ';': 75,\n",
       " '<': 105,\n",
       " '=': 94,\n",
       " '>': 106,\n",
       " '?': 56,\n",
       " '@': 81,\n",
       " 'A': 16,\n",
       " 'B': 15,\n",
       " 'C': 4,\n",
       " 'D': 40,\n",
       " 'E': 46,\n",
       " 'F': 33,\n",
       " 'G': 41,\n",
       " 'H': 57,\n",
       " 'I': 22,\n",
       " 'J': 68,\n",
       " 'K': 49,\n",
       " 'L': 37,\n",
       " 'M': 36,\n",
       " 'N': 35,\n",
       " 'O': 30,\n",
       " 'P': 26,\n",
       " 'Q': 78,\n",
       " 'R': 45,\n",
       " 'S': 38,\n",
       " 'T': 9,\n",
       " 'U': 48,\n",
       " 'UNK': 0,\n",
       " 'V': 14,\n",
       " 'W': 50,\n",
       " 'X': 80,\n",
       " 'Y': 47,\n",
       " 'Z': 71,\n",
       " '[': 91,\n",
       " '\\\\': 97,\n",
       " ']': 92,\n",
       " '^': 86,\n",
       " '_': 102,\n",
       " 'a': 6,\n",
       " 'b': 39,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 12,\n",
       " 'f': 32,\n",
       " 'g': 42,\n",
       " 'h': 28,\n",
       " 'i': 7,\n",
       " 'j': 23,\n",
       " 'k': 55,\n",
       " 'l': 5,\n",
       " 'm': 8,\n",
       " 'n': 19,\n",
       " 'o': 27,\n",
       " 'p': 11,\n",
       " 'q': 51,\n",
       " 'r': 25,\n",
       " 's': 34,\n",
       " 't': 20,\n",
       " 'u': 24,\n",
       " 'v': 44,\n",
       " 'w': 31,\n",
       " 'x': 59,\n",
       " 'y': 10,\n",
       " 'z': 60,\n",
       " '{': 113,\n",
       " '|': 82,\n",
       " '}': 104,\n",
       " '~': 110,\n",
       " '¢': 121,\n",
       " '£': 118,\n",
       " '¥': 125,\n",
       " '§': 114,\n",
       " '©': 122,\n",
       " '«': 116,\n",
       " '®': 119,\n",
       " '°': 90,\n",
       " '±': 124,\n",
       " '»': 115,\n",
       " 'é': 112,\n",
       " '–': 93,\n",
       " '—': 100,\n",
       " '‘': 109,\n",
       " '’': 64,\n",
       " '“': 107,\n",
       " '”': 89,\n",
       " '•': 84,\n",
       " '€': 117,\n",
       " '■': 123,\n",
       " '●': 87,\n",
       " '◦': 103,\n",
       " '☐': 98,\n",
       " '☑': 101,\n",
       " '☒': 99,\n",
       " '✓': 96,\n",
       " 'ﬁ': 88,\n",
       " 'ﬂ': 108}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'C',\n",
       " 5: 'l',\n",
       " 6: 'a',\n",
       " 7: 'i',\n",
       " 8: 'm',\n",
       " 9: 'T',\n",
       " 10: 'y',\n",
       " 11: 'p',\n",
       " 12: 'e',\n",
       " 13: ':',\n",
       " 14: 'V',\n",
       " 15: 'B',\n",
       " 16: 'A',\n",
       " 17: 'c',\n",
       " 18: 'd',\n",
       " 19: 'n',\n",
       " 20: 't',\n",
       " 21: '-',\n",
       " 22: 'I',\n",
       " 23: 'j',\n",
       " 24: 'u',\n",
       " 25: 'r',\n",
       " 26: 'P',\n",
       " 27: 'o',\n",
       " 28: 'h',\n",
       " 29: '/',\n",
       " 30: 'O',\n",
       " 31: 'w',\n",
       " 32: 'f',\n",
       " 33: 'F',\n",
       " 34: 's',\n",
       " 35: 'N',\n",
       " 36: 'M',\n",
       " 37: 'L',\n",
       " 38: 'S',\n",
       " 39: 'b',\n",
       " 40: 'D',\n",
       " 41: 'G',\n",
       " 42: 'g',\n",
       " 43: '1',\n",
       " 44: 'v',\n",
       " 45: 'R',\n",
       " 46: 'E',\n",
       " 47: 'Y',\n",
       " 48: 'U',\n",
       " 49: 'K',\n",
       " 50: 'W',\n",
       " 51: 'q',\n",
       " 52: '3',\n",
       " 53: '2',\n",
       " 54: '.',\n",
       " 55: 'k',\n",
       " 56: '?',\n",
       " 57: 'H',\n",
       " 58: '8',\n",
       " 59: 'x',\n",
       " 60: 'z',\n",
       " 61: '(',\n",
       " 62: ')',\n",
       " 63: '0',\n",
       " 64: '’',\n",
       " 65: '6',\n",
       " 66: '4',\n",
       " 67: '#',\n",
       " 68: 'J',\n",
       " 69: ',',\n",
       " 70: '7',\n",
       " 71: 'Z',\n",
       " 72: '9',\n",
       " 73: '&',\n",
       " 74: '5',\n",
       " 75: ';',\n",
       " 76: '+',\n",
       " 77: '*',\n",
       " 78: 'Q',\n",
       " 79: '$',\n",
       " 80: 'X',\n",
       " 81: '@',\n",
       " 82: '|',\n",
       " 83: \"'\",\n",
       " 84: '•',\n",
       " 85: '%',\n",
       " 86: '^',\n",
       " 87: '●',\n",
       " 88: 'ﬁ',\n",
       " 89: '”',\n",
       " 90: '°',\n",
       " 91: '[',\n",
       " 92: ']',\n",
       " 93: '–',\n",
       " 94: '=',\n",
       " 95: '\"',\n",
       " 96: '✓',\n",
       " 97: '\\\\',\n",
       " 98: '☐',\n",
       " 99: '☒',\n",
       " 100: '—',\n",
       " 101: '☑',\n",
       " 102: '_',\n",
       " 103: '◦',\n",
       " 104: '}',\n",
       " 105: '<',\n",
       " 106: '>',\n",
       " 107: '“',\n",
       " 108: 'ﬂ',\n",
       " 109: '‘',\n",
       " 110: '~',\n",
       " 111: '!',\n",
       " 112: 'é',\n",
       " 113: '{',\n",
       " 114: '§',\n",
       " 115: '»',\n",
       " 116: '«',\n",
       " 117: '€',\n",
       " 118: '£',\n",
       " 119: '®',\n",
       " 120: '\\x0c',\n",
       " 121: '¢',\n",
       " 122: '©',\n",
       " 123: '■',\n",
       " 124: '±',\n",
       " 125: '¥'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 126)    15876       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, None, 512),  784384      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 126)    15876       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1308672     embedding_2[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1024)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 126)    129150      concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,253,958\n",
      "Trainable params: 2,222,206\n",
      "Non-trainable params: 31,752\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(?, ?, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model, encoder_word_embedding_model = build_char_model(latent_dim=latent_dim, num_encoder_tokens=num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 126)         15876     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, None, 512), (None 784384    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 800,260\n",
      "Trainable params: 784,384\n",
      "Non-trainable params: 15,876\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_word_embedding_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hierarichal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word vocab (target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "max_words_seq_len=np.max(words_per_sents_lengths)\n",
    "max_chars_seq_len=np.max(chars_per_words_lengths)\n",
    "print(max_words_seq_len)\n",
    "print(max_chars_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build output vocab on correct words only\n",
    "all_texts = target_texts\n",
    "vocab_to_int, int_to_vocab = build_words_vocab(all_texts)\n",
    "word2int = vocab_to_int\n",
    "int2word = int_to_vocab\n",
    "np.savez('vocab_hier-{}-{}'.format(max_words_seq_len, max_chars_seq_len), char2int=char2int, int2char=int2char, word2int=word2int, int2word=int2word, max_words_seq_len=max_words_seq_len, max_char_seq_len=max_chars_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 0,\n",
       " ' ': 1,\n",
       " '\\t': 2,\n",
       " '\\n': 3,\n",
       " 'Claim': 4,\n",
       " 'Type': 5,\n",
       " 'VB': 6,\n",
       " 'Accident': 7,\n",
       " 'Accidental': 8,\n",
       " 'Injury': 9,\n",
       " 'Information': 10,\n",
       " 'First': 11,\n",
       " 'Name': 12,\n",
       " 'Middle': 13,\n",
       " 'Last': 14,\n",
       " 'Social': 15,\n",
       " 'Security': 16,\n",
       " 'Number': 17,\n",
       " 'Birth': 18,\n",
       " 'Date': 19,\n",
       " 'Gender': 20,\n",
       " 'Language': 21,\n",
       " 'Preference': 22,\n",
       " 'Address': 23,\n",
       " 'Line': 24,\n",
       " 'City': 25,\n",
       " 'Postal': 26,\n",
       " 'Code': 27,\n",
       " 'Country': 28,\n",
       " 'Best': 29,\n",
       " 'Phone': 30,\n",
       " 'to': 31,\n",
       " 'be': 32,\n",
       " 'Reached': 33,\n",
       " 'During': 34,\n",
       " 'the': 35,\n",
       " 'Day': 36,\n",
       " 'Email': 37,\n",
       " 'RADIOLOGY': 38,\n",
       " 'REPORT': 39,\n",
       " 'UNKNOWN': 40,\n",
       " 'Technique': 41,\n",
       " 'views': 42,\n",
       " 'left': 43,\n",
       " 'wrist': 44,\n",
       " 'FINDINGS': 45,\n",
       " 'IMPRESSION': 46,\n",
       " 'No': 47,\n",
       " 'acute': 48,\n",
       " 'osseous': 49,\n",
       " 'abnormality': 50,\n",
       " 'identified': 51,\n",
       " 'Daytime': 52,\n",
       " 'Event': 53,\n",
       " 'Stopped': 54,\n",
       " 'Working': 55,\n",
       " 'Yes': 56,\n",
       " 'Physically': 57,\n",
       " 'at': 58,\n",
       " 'Work': 59,\n",
       " 'Hours': 60,\n",
       " 'Worked': 61,\n",
       " 'on': 62,\n",
       " 'Scheduled': 63,\n",
       " 'Missed': 64,\n",
       " 'Returned': 65,\n",
       " 'Related': 66,\n",
       " 'Time': 67,\n",
       " 'of': 68,\n",
       " 'Diagnosis': 69,\n",
       " 'Arthiscopic': 70,\n",
       " 'surgery': 71,\n",
       " 'Surgery': 72,\n",
       " 'Is': 73,\n",
       " 'Required': 74,\n",
       " 'Indicator': 75,\n",
       " 'Outpatient': 76,\n",
       " 'Medical': 77,\n",
       " 'Provider': 78,\n",
       " 'Physician': 79,\n",
       " 'Roles': 80,\n",
       " 'Treating': 81,\n",
       " 'Patrick': 82,\n",
       " 'Emerson': 83,\n",
       " 'Business': 84,\n",
       " 'Telephone': 85,\n",
       " 'Fax': 86,\n",
       " 'Visit': 87,\n",
       " 'Next': 88,\n",
       " 'Hospitalization': 89,\n",
       " 'Hospital': 90,\n",
       " 'Discharge': 91,\n",
       " 'Procedure': 92,\n",
       " 'Left': 93,\n",
       " 'arthiscopic': 94,\n",
       " 'Employment': 95,\n",
       " 'Employer': 96,\n",
       " 'Policy': 97,\n",
       " 'Electronic': 98,\n",
       " 'Submission': 99,\n",
       " 'Identifier': 100,\n",
       " 'Electronically': 101,\n",
       " 'Signed': 102,\n",
       " 'Fraud': 103,\n",
       " 'Statements': 104,\n",
       " 'Reviewed': 105,\n",
       " 'and': 106,\n",
       " 'unum': 107,\n",
       " 'The': 108,\n",
       " 'Benefits': 109,\n",
       " 'Center': 110,\n",
       " 'Not': 111,\n",
       " 'for': 112,\n",
       " 'FMLA': 113,\n",
       " 'Requests': 114,\n",
       " 'Insured': 115,\n",
       " '’': 116,\n",
       " 's': 117,\n",
       " 'Signature': 118,\n",
       " 'Printed': 119,\n",
       " 'Unum': 120,\n",
       " 'Confirmation': 121,\n",
       " 'Coverage': 122,\n",
       " 'Group': 123,\n",
       " 'Customer': 124,\n",
       " 'EE': 125,\n",
       " 'Effective': 126,\n",
       " 'Employee': 127,\n",
       " 'Acc': 128,\n",
       " 'January': 129,\n",
       " 'Wellness': 130,\n",
       " 'Benefit': 131,\n",
       " 'Total': 132,\n",
       " 'Monthly': 133,\n",
       " 'Premium': 134,\n",
       " 'Montly': 135,\n",
       " 'Payroll': 136,\n",
       " 'Deduction': 137,\n",
       " 'MRI': 138,\n",
       " 'OF': 139,\n",
       " 'THE': 140,\n",
       " 'LEFT': 141,\n",
       " 'WRIST': 142,\n",
       " 'WITHOUT': 143,\n",
       " 'CONTRAST': 144,\n",
       " 'COMPARISON': 145,\n",
       " 'None': 146,\n",
       " 'These': 147,\n",
       " 'results': 148,\n",
       " 'were': 149,\n",
       " 'faxed': 150,\n",
       " 'Gelovich': 151,\n",
       " 'signed': 152,\n",
       " 'by': 153,\n",
       " 'Stephen': 154,\n",
       " 'Bravo': 155,\n",
       " 'Dependent': 156,\n",
       " 'Detail': 157,\n",
       " 'Billed': 158,\n",
       " 'Amounts': 159,\n",
       " 'Contract': 160,\n",
       " 'Adjustment': 161,\n",
       " 'Allowed': 162,\n",
       " 'Amount': 163,\n",
       " 'Covered': 164,\n",
       " 'Reason': 165,\n",
       " 'Deductible': 166,\n",
       " 'Other': 167,\n",
       " 'Carrier': 168,\n",
       " 'Paid': 169,\n",
       " 'Patient': 170,\n",
       " 'Responsibility': 171,\n",
       " 'Important': 172,\n",
       " 'about': 173,\n",
       " 'Your': 174,\n",
       " 'Appeal': 175,\n",
       " 'Rights': 176,\n",
       " 'All': 177,\n",
       " 'Languages': 178,\n",
       " 'Contact': 179,\n",
       " 'Did': 180,\n",
       " 'You': 181,\n",
       " 'Know': 182,\n",
       " 'Specialty': 183,\n",
       " 'Orthopedic': 184,\n",
       " 'Surgeon': 185,\n",
       " 'Zachary': 186,\n",
       " 'Jager': 187,\n",
       " 'Unknown': 188,\n",
       " 'Kari': 189,\n",
       " 'Lund': 190,\n",
       " 'Orthopedist': 191,\n",
       " 'Dan': 192,\n",
       " 'Palmer': 193,\n",
       " 'On': 194,\n",
       " '&': 195,\n",
       " 'May': 196,\n",
       " 'Spouse': 197,\n",
       " 'Child': 198,\n",
       " 'BLACK': 199,\n",
       " 'HILLS': 200,\n",
       " 'ORTHOPEDIC': 201,\n",
       " 'CENTER': 202,\n",
       " 'PC': 203,\n",
       " 'LAST': 204,\n",
       " 'PMT': 205,\n",
       " 'AMOUNT': 206,\n",
       " 'DUE': 207,\n",
       " 'DATE': 208,\n",
       " 'PAGE': 209,\n",
       " 'STATEMENT': 210,\n",
       " 'Ins': 211,\n",
       " 'Description': 212,\n",
       " 'E': 213,\n",
       " 'm': 214,\n",
       " 'New': 215,\n",
       " 'Moderat': 216,\n",
       " 'S': 217,\n",
       " 'Clo': 218,\n",
       " 'Tx': 219,\n",
       " 'Phalangealfx': 220,\n",
       " 'Finger': 221,\n",
       " 'Splint': 222,\n",
       " 'Offic': 223,\n",
       " 'Cons': 224,\n",
       " 'Moderate': 225,\n",
       " 'Sever': 226,\n",
       " 'Rad': 227,\n",
       " 'Exam': 228,\n",
       " 'Mini': 229,\n",
       " 'Views': 230,\n",
       " 'Applic': 231,\n",
       " 'Hand': 232,\n",
       " 'Lower': 233,\n",
       " 'Forearm': 234,\n",
       " 'Fiberglass': 235,\n",
       " 'gauntlet': 236,\n",
       " 'Cast': 237,\n",
       " 'Yrs': 238,\n",
       " 'Charge': 239,\n",
       " 'Pmt': 240,\n",
       " 'Pat': 241,\n",
       " 'Adjust': 242,\n",
       " 'Days': 243,\n",
       " 'Balance': 244,\n",
       " 'Pending': 245,\n",
       " 'Now': 246,\n",
       " 'Due': 247,\n",
       " 'Message': 248,\n",
       " 'Account': 249,\n",
       " 'Statement': 250,\n",
       " 'Billing': 251,\n",
       " 'Questions': 252,\n",
       " 'Choice': 253,\n",
       " 'Health': 254,\n",
       " 'Administrators': 255,\n",
       " 'Forwarding': 256,\n",
       " 'Service': 257,\n",
       " 'Requested': 258,\n",
       " 'REGIONAL': 259,\n",
       " 'HEALTH': 260,\n",
       " 'INC': 261,\n",
       " 'Participant': 262,\n",
       " 'ID': 263,\n",
       " 'Original': 264,\n",
       " 'Print': 265,\n",
       " 'Website': 266,\n",
       " 'DEA': 267,\n",
       " 'By': 268,\n",
       " 'Plan': 269,\n",
       " 'DEDUCTIBLE': 270,\n",
       " 'OUT': 271,\n",
       " 'POCKET': 272,\n",
       " 'Regional': 273,\n",
       " 'Inc': 274,\n",
       " 'Sign': 275,\n",
       " 'up': 276,\n",
       " 'paperless': 277,\n",
       " 'Individual': 278,\n",
       " 'Family': 279,\n",
       " 'Out': 280,\n",
       " 'Network': 281,\n",
       " 'Karl': 282,\n",
       " 'Services': 283,\n",
       " 'exam': 284,\n",
       " 'hand': 285,\n",
       " 'Modifiers': 286,\n",
       " 'TC': 287,\n",
       " 'RT': 288,\n",
       " 'Appeals': 289,\n",
       " 'This': 290,\n",
       " 'Qualified': 291,\n",
       " 'sign': 292,\n",
       " 'language': 293,\n",
       " 'interpreters': 294,\n",
       " 'written': 295,\n",
       " 'in': 296,\n",
       " 'other': 297,\n",
       " 'languages': 298,\n",
       " 'Jacquelin': 299,\n",
       " 'Brainard': 300,\n",
       " 'Compliance': 301,\n",
       " 'Officer': 302,\n",
       " 'or': 303,\n",
       " 'mail': 304,\n",
       " 'phone': 305,\n",
       " 'Department': 306,\n",
       " 'Human': 307,\n",
       " 'Complaint': 308,\n",
       " 'forms': 309,\n",
       " 'are': 310,\n",
       " 'available': 311,\n",
       " 'EXPLANATION': 312,\n",
       " 'BENEFITS': 313,\n",
       " 'Retain': 314,\n",
       " 'For': 315,\n",
       " 'Tax': 316,\n",
       " 'Purposes': 317,\n",
       " 'Status': 318,\n",
       " 'Period': 319,\n",
       " 'Totals': 320,\n",
       " 'DAKOTA': 321,\n",
       " 'Automated': 322,\n",
       " 'Attendant': 323,\n",
       " 'hours': 324,\n",
       " 'a': 325,\n",
       " 'day': 326,\n",
       " 'Payments': 327,\n",
       " 'Please': 328,\n",
       " 'Call': 329,\n",
       " 'Upon': 330,\n",
       " 'Receipt': 331,\n",
       " 'Pay': 332,\n",
       " 'Online': 333,\n",
       " '|': 334,\n",
       " 'Update': 335,\n",
       " 'Info': 336,\n",
       " 'See': 337,\n",
       " 'Details': 338,\n",
       " 'Back': 339,\n",
       " 'SHOW': 340,\n",
       " 'PAID': 341,\n",
       " 'HERE': 342,\n",
       " 'MAKE': 343,\n",
       " 'CHECKS': 344,\n",
       " 'TO': 345,\n",
       " 'INSUR': 346,\n",
       " 'PENDING': 347,\n",
       " 'PATIENT': 348,\n",
       " 'BALANCE': 349,\n",
       " 'EXAM': 350,\n",
       " 'HAND': 351,\n",
       " 'THORAC': 352,\n",
       " 'SPINE': 353,\n",
       " 'COMMERCIAL': 354,\n",
       " 'NON': 355,\n",
       " 'ALLOWED': 356,\n",
       " 'CT': 357,\n",
       " 'ABD': 358,\n",
       " 'PELV': 359,\n",
       " 'PAYMENT': 360,\n",
       " 'CHEST': 361,\n",
       " 'VIEWS': 362,\n",
       " 'Summary': 363,\n",
       " 'HARGES': 364,\n",
       " 'Of': 365,\n",
       " 'Today': 366,\n",
       " \"'s\": 367,\n",
       " 'Ethnicity': 368,\n",
       " 'Hispanic': 369,\n",
       " 'Latino': 370,\n",
       " 'Preferred': 371,\n",
       " 'English': 372,\n",
       " 'visit': 373,\n",
       " 'with': 374,\n",
       " 'Suzanne': 375,\n",
       " 'Newsom': 376,\n",
       " 'CNP': 377,\n",
       " '•': 378,\n",
       " 'Lethargy': 379,\n",
       " 'cough': 380,\n",
       " 'Vitals': 381,\n",
       " 'lbs': 382,\n",
       " 'kg': 383,\n",
       " 'Wt': 384,\n",
       " 'Temp': 385,\n",
       " 'F': 386,\n",
       " 'HR': 387,\n",
       " 'Oxygen': 388,\n",
       " 'sat': 389,\n",
       " 'Allergies': 390,\n",
       " 'Amoxicillin': 391,\n",
       " 'rash': 392,\n",
       " 'possible': 393,\n",
       " 'hives': 394,\n",
       " 'Active': 395,\n",
       " 'Diagnoses': 396,\n",
       " 'Include': 397,\n",
       " 'Acute': 398,\n",
       " 'frontal': 399,\n",
       " 'sinusitis': 400,\n",
       " 'unspecified': 401,\n",
       " 'Dizziness': 402,\n",
       " 'giddiness': 403,\n",
       " 'Medication': 404,\n",
       " 'List': 405,\n",
       " 'medications': 406,\n",
       " 'you': 407,\n",
       " 'Taking': 408,\n",
       " 'Zyrtec': 409,\n",
       " 'Childrens': 410,\n",
       " 'Allergy': 411,\n",
       " 'Notes': 412,\n",
       " 'Tests': 413,\n",
       " 'Labs': 414,\n",
       " 'Illumigene': 415,\n",
       " 'MYCO': 416,\n",
       " 'http': 417,\n",
       " 'BASIC': 418,\n",
       " 'METABOLIC': 419,\n",
       " 'SODIUM': 420,\n",
       " 'Range': 421,\n",
       " 'POTASSIUM': 422,\n",
       " 'CHLORIDE': 423,\n",
       " 'GLUCOSE': 424,\n",
       " 'BUN': 425,\n",
       " 'CREATININE': 426,\n",
       " 'CALCIUM': 427,\n",
       " 'CREA': 428,\n",
       " 'RATIO': 429,\n",
       " 'Ratio': 430,\n",
       " 'ANION': 431,\n",
       " 'GAP': 432,\n",
       " 'Calc': 433,\n",
       " 'CBC': 434,\n",
       " 'DIFF': 435,\n",
       " 'WBC': 436,\n",
       " 'RBC': 437,\n",
       " 'HGB': 438,\n",
       " 'HCT': 439,\n",
       " 'MCV': 440,\n",
       " 'fL': 441,\n",
       " 'MCH': 442,\n",
       " 'pg': 443,\n",
       " 'MCHC': 444,\n",
       " 'MPV': 445,\n",
       " 'PLATELETS': 446,\n",
       " 'NEUTROPHILS': 447,\n",
       " 'LYMPHOCYTES': 448,\n",
       " 'MONOCYTES': 449,\n",
       " 'Conditions': 450,\n",
       " 'Problem': 451,\n",
       " 'Idiopathic': 452,\n",
       " 'urticaria': 453,\n",
       " 'document': 454,\n",
       " 'wish': 455,\n",
       " 'keep': 456,\n",
       " 'Policyholder': 457,\n",
       " 'Owner': 458,\n",
       " 'Eastside': 459,\n",
       " 'Jasminder': 460,\n",
       " 'Singh': 461,\n",
       " 'Dev': 462,\n",
       " 'PA': 463,\n",
       " 'EXCUSE': 464,\n",
       " 'east': 465,\n",
       " 'side': 466,\n",
       " 'medical': 467,\n",
       " 'center': 468,\n",
       " 'April': 469,\n",
       " 'Weekly': 470,\n",
       " 'DOB': 471,\n",
       " 'Ph': 472,\n",
       " 'MR': 473,\n",
       " 'Primary': 474,\n",
       " 'Thoracic': 475,\n",
       " 'Strain': 476,\n",
       " 'have': 477,\n",
       " 'strained': 478,\n",
       " 'your': 479,\n",
       " 'thoracic': 480,\n",
       " 'spine': 481,\n",
       " 'Page': 482,\n",
       " 'IF': 483,\n",
       " 'ANY': 484,\n",
       " 'FOLLOWING': 485,\n",
       " 'OCCURS': 486,\n",
       " 'feel': 487,\n",
       " 'weakness': 488,\n",
       " 'arms': 489,\n",
       " 'legs': 490,\n",
       " 'severe': 491,\n",
       " 'increase': 492,\n",
       " 'pain': 493,\n",
       " 'Lumbosacral': 494,\n",
       " 'weak': 495,\n",
       " 'becomes': 496,\n",
       " 'more': 497,\n",
       " 'Follow': 498,\n",
       " 'Up': 499,\n",
       " 'What': 500,\n",
       " 'To': 501,\n",
       " 'Do': 502,\n",
       " 'Take': 503,\n",
       " 'all': 504,\n",
       " 'as': 505,\n",
       " 'directed': 506,\n",
       " 'Additional': 507,\n",
       " 'Prescriptions': 508,\n",
       " 'Written': 509,\n",
       " 'Prescriber': 510,\n",
       " 'Paper': 511,\n",
       " 'Prescription': 512,\n",
       " 'given': 513,\n",
       " 'patient': 514,\n",
       " 'Preventative': 515,\n",
       " 'Instructions': 516,\n",
       " 'knee': 517,\n",
       " 'injury': 518,\n",
       " 'David': 519,\n",
       " 'Bruce': 520,\n",
       " 'Identiﬁer': 521,\n",
       " 'June': 522,\n",
       " 'Explanation': 523,\n",
       " 'Gap': 524,\n",
       " 'no': 525,\n",
       " 'concussion': 526,\n",
       " 'Assistant': 527,\n",
       " 'devin': 528,\n",
       " 'conrad': 529,\n",
       " 'September': 530,\n",
       " 'ACCIDENT': 531,\n",
       " 'CLAIM': 532,\n",
       " 'FORM': 533,\n",
       " 'ATTENDING': 534,\n",
       " 'PHYSICIAN': 535,\n",
       " 'PLEASE': 536,\n",
       " 'PRINT': 537,\n",
       " 'PART': 538,\n",
       " 'I': 539,\n",
       " 'BE': 540,\n",
       " 'COMPLETED': 541,\n",
       " 'BY': 542,\n",
       " 'first': 543,\n",
       " 'unable': 544,\n",
       " 'work': 545,\n",
       " 'Expected': 546,\n",
       " 'Delivery': 547,\n",
       " 'Actual': 548,\n",
       " 'Unable': 549,\n",
       " 'Vaginal': 550,\n",
       " 'per': 551,\n",
       " 'Continued': 552,\n",
       " 'Facility': 553,\n",
       " 'State': 554,\n",
       " 'Zip': 555,\n",
       " 'Performed': 556,\n",
       " 'ICD': 557,\n",
       " 'Attending': 558,\n",
       " 'Degree': 559,\n",
       " 'A': 560,\n",
       " 'check': 561,\n",
       " 'type': 562,\n",
       " 'claim': 563,\n",
       " 'filing': 564,\n",
       " 'B': 565,\n",
       " 'About': 566,\n",
       " 'Suffix': 567,\n",
       " 'MI': 568,\n",
       " 'Spanish': 569,\n",
       " 'Short': 570,\n",
       " 'Term': 571,\n",
       " 'Disability': 572,\n",
       " 'Long': 573,\n",
       " 'Life': 574,\n",
       " 'Insurance': 575,\n",
       " 'Voluntary': 576,\n",
       " 'Was': 577,\n",
       " 'this': 578,\n",
       " 'motor': 579,\n",
       " 'vehicle': 580,\n",
       " 'accident': 581,\n",
       " 'Physicians': 582,\n",
       " 'Hospitals': 583,\n",
       " 'Considerations': 584,\n",
       " 'Male': 585,\n",
       " 'Female': 586,\n",
       " 'Surgical': 587,\n",
       " 'CPT': 588,\n",
       " 'X': 589,\n",
       " 'My': 590,\n",
       " 'Member': 591,\n",
       " 'Relationship': 592,\n",
       " 'person': 593,\n",
       " 'Marital': 594,\n",
       " 'Single': 595,\n",
       " 'Occ': 596,\n",
       " 'Title': 597,\n",
       " 'ResinMixer': 598,\n",
       " 'Hire': 599,\n",
       " 'Termination': 600,\n",
       " 'ATW': 601,\n",
       " 'Limitations': 602,\n",
       " 'Permitted': 603,\n",
       " 'Months': 604,\n",
       " 'Office': 605,\n",
       " 'Crane': 606,\n",
       " 'Composites': 607,\n",
       " 'Florence': 608,\n",
       " 'Earn': 609,\n",
       " 'Change': 610,\n",
       " 'Leave': 611,\n",
       " 'Absence': 612,\n",
       " 'Record': 613,\n",
       " 'Loaded': 614,\n",
       " 'Residence': 615,\n",
       " 'Physical': 616,\n",
       " 'Access': 617,\n",
       " 'Home': 618,\n",
       " 'Supervisor': 619,\n",
       " 'Coverages': 620,\n",
       " 'Product': 621,\n",
       " 'Flex': 622,\n",
       " 'Funding': 623,\n",
       " 'Fully': 624,\n",
       " 'Division': 625,\n",
       " 'PEG': 626,\n",
       " 'Eff': 627,\n",
       " 'Earnings': 628,\n",
       " 'Hourly': 629,\n",
       " 'Mode': 630,\n",
       " 'After': 631,\n",
       " 'Report': 632,\n",
       " 'ASO': 633,\n",
       " 'Self': 634,\n",
       " 'If': 635,\n",
       " 'yes': 636,\n",
       " 'dates': 637,\n",
       " 'admission': 638,\n",
       " 'Treatment': 639,\n",
       " 'Nature': 640,\n",
       " 'estimated': 641,\n",
       " 'duration': 642,\n",
       " 'treatments': 643,\n",
       " 'Job': 644,\n",
       " 'description': 645,\n",
       " 'is': 646,\n",
       " 'attached': 647,\n",
       " 'if': 648,\n",
       " 'checked': 649,\n",
       " 'here': 650,\n",
       " 'address': 651,\n",
       " 'Care': 652,\n",
       " 'DETAILS': 653,\n",
       " 'Dates': 654,\n",
       " 'including': 655,\n",
       " 'Confinement': 656,\n",
       " 'please': 657,\n",
       " 'provide': 658,\n",
       " 'following': 659,\n",
       " 'advice': 660,\n",
       " 'stop': 661,\n",
       " 'working': 662,\n",
       " 'what': 663,\n",
       " 'date': 664,\n",
       " 'Mgmt': 665,\n",
       " 'Svc': 666,\n",
       " 'Applicable': 667,\n",
       " 'Deductions': 668,\n",
       " 'Schedule': 669,\n",
       " 'Per': 670,\n",
       " 'Week': 671,\n",
       " 'Sick': 672,\n",
       " 'Variable': 673,\n",
       " 'Sunday': 674,\n",
       " 'Monday': 675,\n",
       " 'Tuesday': 676,\n",
       " 'Wednesday': 677,\n",
       " 'Thursday': 678,\n",
       " 'Friday': 679,\n",
       " 'Saturday': 680,\n",
       " 'SHORT': 681,\n",
       " 'TERM': 682,\n",
       " 'DISABILITY': 683,\n",
       " 'Hospitalized': 684,\n",
       " 'explain': 685,\n",
       " 'last': 686,\n",
       " 'office': 687,\n",
       " 'next': 688,\n",
       " 'Height': 689,\n",
       " 'Weight': 690,\n",
       " 'Secondary': 691,\n",
       " 'Has': 692,\n",
       " 'been': 693,\n",
       " 'hospitalized': 694,\n",
       " 'performed': 695,\n",
       " 'procedure': 696,\n",
       " 'was': 697,\n",
       " 'Functional': 698,\n",
       " 'Capacity': 699,\n",
       " 'Restrictions': 700,\n",
       " 'ELIZABETH': 701,\n",
       " 'EDGEWOOD': 702,\n",
       " 'FACESHEET': 703,\n",
       " 'MRN': 704,\n",
       " 'Sex': 705,\n",
       " 'Demographics': 706,\n",
       " 'SSN': 707,\n",
       " 'Reg': 708,\n",
       " 'Verified': 709,\n",
       " 'PCP': 710,\n",
       " 'Renew': 711,\n",
       " 'Admission': 712,\n",
       " 'Admitting': 713,\n",
       " 'Larkin': 714,\n",
       " 'John': 715,\n",
       " 'MD': 716,\n",
       " 'Elective': 717,\n",
       " 'Incomplete': 718,\n",
       " 'Area': 719,\n",
       " 'SERVICE': 720,\n",
       " 'AREA': 721,\n",
       " 'EDG': 722,\n",
       " 'SC': 723,\n",
       " 'CRESTVIEW': 724,\n",
       " 'Discharged': 725,\n",
       " 'Confirmed': 726,\n",
       " 'HOSE': 727,\n",
       " 'ital': 728,\n",
       " 'Acct': 729,\n",
       " 'Class': 730,\n",
       " 'Same': 731,\n",
       " 'Guarantor': 732,\n",
       " 'Relation': 733,\n",
       " 'Pt': 734,\n",
       " 'SEH': 735,\n",
       " 'Precert': 736,\n",
       " 'Subscriber': 737,\n",
       " 'Operative': 738,\n",
       " 'Brief': 739,\n",
       " 'Op': 740,\n",
       " 'Note': 741,\n",
       " 'OP': 742,\n",
       " 'Adm': 743,\n",
       " 'continued': 744,\n",
       " 'Author': 745,\n",
       " 'J': 746,\n",
       " 'Filed': 747,\n",
       " 'Editor': 748,\n",
       " 'Elizabeth': 749,\n",
       " 'Healthcare': 750,\n",
       " 'NOTE': 751,\n",
       " 'Body': 752,\n",
       " 'mass': 753,\n",
       " 'index': 754,\n",
       " 'PROCEDURE': 755,\n",
       " 'SURGEON': 756,\n",
       " 'Role': 757,\n",
       " 'ANESTHESIA': 758,\n",
       " 'General': 759,\n",
       " 'SPECIMENS': 760,\n",
       " 'specimens': 761,\n",
       " 'log': 762,\n",
       " 'ESTIMATED': 763,\n",
       " 'BLOOD': 764,\n",
       " 'LOSS': 765,\n",
       " 'PROC': 766,\n",
       " 'COURSE': 767,\n",
       " 'PACU': 768,\n",
       " 'OPERATION': 769,\n",
       " 'Broken': 770,\n",
       " 'big': 771,\n",
       " 'toe': 772,\n",
       " 'foot': 773,\n",
       " 'Todd': 774,\n",
       " 'Francis': 775,\n",
       " 'Podiatrist': 776,\n",
       " 'Ryan': 777,\n",
       " 'Kish': 778,\n",
       " 'Toledo': 779,\n",
       " 'ER': 780,\n",
       " 'Xray': 781,\n",
       " 'July': 782,\n",
       " 'Paramount': 783,\n",
       " 'ProMedica': 784,\n",
       " 'LINE': 785,\n",
       " 'AUTHORIZATION': 786,\n",
       " 'NO': 787,\n",
       " 'CODE': 788,\n",
       " 'MODIFIER': 789,\n",
       " 'DIAGNOSIS': 790,\n",
       " 'EXPLAIN': 791,\n",
       " 'BILLED': 792,\n",
       " 'PARAMOUNT': 793,\n",
       " 'LT': 794,\n",
       " 'Indicates': 795,\n",
       " 'additional': 796,\n",
       " 'information': 797,\n",
       " 'C': 798,\n",
       " 'DPM': 799,\n",
       " 'EMS': 800,\n",
       " 'Christine': 801,\n",
       " 'Nolen': 802,\n",
       " 'Waukesha': 803,\n",
       " 'Memorial': 804,\n",
       " 'Cleaning': 805,\n",
       " 'xray': 806,\n",
       " 'bandage': 807,\n",
       " 'MONTANO': 808,\n",
       " 'CI': 809,\n",
       " 'Web': 810,\n",
       " 'user': 811,\n",
       " 'notes': 812,\n",
       " 'statements': 813,\n",
       " 'PROHEALTH': 814,\n",
       " 'CARE': 815,\n",
       " 'SERVICES': 816,\n",
       " 'GUARANTOR': 817,\n",
       " 'NAME': 818,\n",
       " 'DESCRIPTION': 819,\n",
       " 'PAYMENTS': 820,\n",
       " 'ADJUSTMENTS': 821,\n",
       " 'PATIENTS': 822,\n",
       " 'INVOICE': 823,\n",
       " 'NUMBER': 824,\n",
       " 'Previous': 825,\n",
       " 'CURRENT': 826,\n",
       " 'TOTAL': 827,\n",
       " 'VISIT': 828,\n",
       " 'PAY': 829,\n",
       " 'THIS': 830,\n",
       " 'RETURN': 831,\n",
       " 'PORTION': 832,\n",
       " 'WITH': 833,\n",
       " 'YOUR': 834,\n",
       " 'MASTERCARD': 835,\n",
       " 'DISCOVER': 836,\n",
       " 'VISA': 837,\n",
       " 'Enclosed': 838,\n",
       " 'CHECK': 839,\n",
       " 'PAYABLE': 840,\n",
       " 'EMERGENCY': 841,\n",
       " 'MEDICAL': 842,\n",
       " 'ASSOCIATES': 843,\n",
       " 'PHONE': 844,\n",
       " 'ADDRESSEE': 845,\n",
       " 'INDUSTRIAL': 846,\n",
       " 'LOOP': 847,\n",
       " 'ACCOUNT': 848,\n",
       " \"'S\": 849,\n",
       " 'DEPT': 850,\n",
       " 'PPO': 851,\n",
       " 'ADJ': 852,\n",
       " 'UMR': 853,\n",
       " 'FISERV': 854,\n",
       " 'WI': 855,\n",
       " 'ON': 856,\n",
       " 'OVER': 857,\n",
       " 'DAYS': 858,\n",
       " 'STMT': 859,\n",
       " 'DOCTOR': 860,\n",
       " 'LEGEND': 861,\n",
       " 'NOLEN': 862,\n",
       " 'CHRISTINE': 863,\n",
       " 'D': 864,\n",
       " 'COMMENTS': 865,\n",
       " 'PRIMARY': 866,\n",
       " 'SECONDARY': 867,\n",
       " 'Concussion': 868,\n",
       " 'Souha': 869,\n",
       " 'Hakim': 870,\n",
       " 'MedExpress': 871,\n",
       " 'Codes': 872,\n",
       " 'Urgent': 873,\n",
       " 'Clairn': 874,\n",
       " 'ME': 875,\n",
       " 'Seen': 876,\n",
       " 'Vijay': 877,\n",
       " 'Patel': 878,\n",
       " 'Holder': 879,\n",
       " 'Qty': 880,\n",
       " 'Clinical': 881,\n",
       " 'Chief': 882,\n",
       " 'Penicillins': 883,\n",
       " 'Rash': 884,\n",
       " 'Taken': 885,\n",
       " 'BP': 886,\n",
       " 'mmHg': 887,\n",
       " 'PULSE': 888,\n",
       " 'bpm': 889,\n",
       " 'RESP': 890,\n",
       " 'TEMP': 891,\n",
       " 'WEIGHT': 892,\n",
       " 'lb': 893,\n",
       " 'ft': 894,\n",
       " 'BMI': 895,\n",
       " 'SAT': 896,\n",
       " 'Current': 897,\n",
       " 'Meds': 898,\n",
       " 'ACTIVE': 899,\n",
       " 'albuterol': 900,\n",
       " 'sulfate': 901,\n",
       " 'Encounter': 902,\n",
       " 'Progress': 903,\n",
       " 'none': 904,\n",
       " 'Subjective': 905,\n",
       " 'History': 906,\n",
       " 'provided': 907,\n",
       " 'dad': 908,\n",
       " 'interpreter': 909,\n",
       " 'used': 910,\n",
       " 'presents': 911,\n",
       " 'urgent': 912,\n",
       " 'care': 913,\n",
       " 'Review': 914,\n",
       " 'Systems': 915,\n",
       " 'Cardiovascular': 916,\n",
       " 'Negative': 917,\n",
       " 'chest': 918,\n",
       " 'Skin': 919,\n",
       " 'Neurological': 920,\n",
       " 'headaches': 921,\n",
       " 'Objective': 922,\n",
       " 'HENT': 923,\n",
       " 'Right': 924,\n",
       " 'Ear': 925,\n",
       " 'Tympanic': 926,\n",
       " 'membrane': 927,\n",
       " 'normal': 928,\n",
       " 'Nose': 929,\n",
       " 'Oropharynx': 930,\n",
       " 'clear': 931,\n",
       " 'Eyes': 932,\n",
       " 'Conjunctivae': 933,\n",
       " 'EOM': 934,\n",
       " 'Neck': 935,\n",
       " 'supple': 936,\n",
       " 'rigidity': 937,\n",
       " 'murmur': 938,\n",
       " 'heard': 939,\n",
       " 'Lymphadenopathy': 940,\n",
       " 'He': 941,\n",
       " 'has': 942,\n",
       " 'cervical': 943,\n",
       " 'adenopathy': 944,\n",
       " 'alert': 945,\n",
       " 'warm': 946,\n",
       " 'noted': 947,\n",
       " 'Assessment': 948,\n",
       " 'advise': 949,\n",
       " 'SS': 950,\n",
       " 'Penobscot': 951,\n",
       " 'Community': 952,\n",
       " 'Suite': 953,\n",
       " 'Medicine': 954,\n",
       " 'Mental': 955,\n",
       " 'FAX': 956,\n",
       " 'Transmission': 957,\n",
       " 'Sheet': 958,\n",
       " 'FROM': 959,\n",
       " 'Ext': 960,\n",
       " 'number': 961,\n",
       " 'pages': 962,\n",
       " 'cover': 963,\n",
       " 'page': 964,\n",
       " 'Thank': 965,\n",
       " 'Revised': 966,\n",
       " 'Imaging': 967,\n",
       " 'MaineCare': 968,\n",
       " 'FQHC': 969,\n",
       " 'Low': 970,\n",
       " 'JT': 971,\n",
       " 'Rt': 972,\n",
       " 'Erin': 973,\n",
       " 'Barker': 974,\n",
       " 'Joseph': 975,\n",
       " 'Ordering': 976,\n",
       " 'BARKER': 977,\n",
       " 'ERIN': 978,\n",
       " 'RIGHT': 979,\n",
       " 'KNEE': 980,\n",
       " 'INTERCONDYLAR': 981,\n",
       " 'SPACE': 982,\n",
       " 'ACL': 983,\n",
       " 'PCL': 984,\n",
       " 'intact': 985,\n",
       " 'Unremarkable': 986,\n",
       " 'marrow': 987,\n",
       " 'signal': 988,\n",
       " 'T': 989,\n",
       " 'DICTATION': 990,\n",
       " 'LOCATION': 991,\n",
       " 'MPSYNERNET': 992,\n",
       " 'Reading': 993,\n",
       " 'KASPER': 994,\n",
       " 'JARED': 995,\n",
       " 'Down': 996,\n",
       " 'East': 997,\n",
       " 'Orthopedics': 998,\n",
       " 'Sports': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'Claim',\n",
       " 5: 'Type',\n",
       " 6: 'VB',\n",
       " 7: 'Accident',\n",
       " 8: 'Accidental',\n",
       " 9: 'Injury',\n",
       " 10: 'Information',\n",
       " 11: 'First',\n",
       " 12: 'Name',\n",
       " 13: 'Middle',\n",
       " 14: 'Last',\n",
       " 15: 'Social',\n",
       " 16: 'Security',\n",
       " 17: 'Number',\n",
       " 18: 'Birth',\n",
       " 19: 'Date',\n",
       " 20: 'Gender',\n",
       " 21: 'Language',\n",
       " 22: 'Preference',\n",
       " 23: 'Address',\n",
       " 24: 'Line',\n",
       " 25: 'City',\n",
       " 26: 'Postal',\n",
       " 27: 'Code',\n",
       " 28: 'Country',\n",
       " 29: 'Best',\n",
       " 30: 'Phone',\n",
       " 31: 'to',\n",
       " 32: 'be',\n",
       " 33: 'Reached',\n",
       " 34: 'During',\n",
       " 35: 'the',\n",
       " 36: 'Day',\n",
       " 37: 'Email',\n",
       " 38: 'RADIOLOGY',\n",
       " 39: 'REPORT',\n",
       " 40: 'UNKNOWN',\n",
       " 41: 'Technique',\n",
       " 42: 'views',\n",
       " 43: 'left',\n",
       " 44: 'wrist',\n",
       " 45: 'FINDINGS',\n",
       " 46: 'IMPRESSION',\n",
       " 47: 'No',\n",
       " 48: 'acute',\n",
       " 49: 'osseous',\n",
       " 50: 'abnormality',\n",
       " 51: 'identified',\n",
       " 52: 'Daytime',\n",
       " 53: 'Event',\n",
       " 54: 'Stopped',\n",
       " 55: 'Working',\n",
       " 56: 'Yes',\n",
       " 57: 'Physically',\n",
       " 58: 'at',\n",
       " 59: 'Work',\n",
       " 60: 'Hours',\n",
       " 61: 'Worked',\n",
       " 62: 'on',\n",
       " 63: 'Scheduled',\n",
       " 64: 'Missed',\n",
       " 65: 'Returned',\n",
       " 66: 'Related',\n",
       " 67: 'Time',\n",
       " 68: 'of',\n",
       " 69: 'Diagnosis',\n",
       " 70: 'Arthiscopic',\n",
       " 71: 'surgery',\n",
       " 72: 'Surgery',\n",
       " 73: 'Is',\n",
       " 74: 'Required',\n",
       " 75: 'Indicator',\n",
       " 76: 'Outpatient',\n",
       " 77: 'Medical',\n",
       " 78: 'Provider',\n",
       " 79: 'Physician',\n",
       " 80: 'Roles',\n",
       " 81: 'Treating',\n",
       " 82: 'Patrick',\n",
       " 83: 'Emerson',\n",
       " 84: 'Business',\n",
       " 85: 'Telephone',\n",
       " 86: 'Fax',\n",
       " 87: 'Visit',\n",
       " 88: 'Next',\n",
       " 89: 'Hospitalization',\n",
       " 90: 'Hospital',\n",
       " 91: 'Discharge',\n",
       " 92: 'Procedure',\n",
       " 93: 'Left',\n",
       " 94: 'arthiscopic',\n",
       " 95: 'Employment',\n",
       " 96: 'Employer',\n",
       " 97: 'Policy',\n",
       " 98: 'Electronic',\n",
       " 99: 'Submission',\n",
       " 100: 'Identifier',\n",
       " 101: 'Electronically',\n",
       " 102: 'Signed',\n",
       " 103: 'Fraud',\n",
       " 104: 'Statements',\n",
       " 105: 'Reviewed',\n",
       " 106: 'and',\n",
       " 107: 'unum',\n",
       " 108: 'The',\n",
       " 109: 'Benefits',\n",
       " 110: 'Center',\n",
       " 111: 'Not',\n",
       " 112: 'for',\n",
       " 113: 'FMLA',\n",
       " 114: 'Requests',\n",
       " 115: 'Insured',\n",
       " 116: '’',\n",
       " 117: 's',\n",
       " 118: 'Signature',\n",
       " 119: 'Printed',\n",
       " 120: 'Unum',\n",
       " 121: 'Confirmation',\n",
       " 122: 'Coverage',\n",
       " 123: 'Group',\n",
       " 124: 'Customer',\n",
       " 125: 'EE',\n",
       " 126: 'Effective',\n",
       " 127: 'Employee',\n",
       " 128: 'Acc',\n",
       " 129: 'January',\n",
       " 130: 'Wellness',\n",
       " 131: 'Benefit',\n",
       " 132: 'Total',\n",
       " 133: 'Monthly',\n",
       " 134: 'Premium',\n",
       " 135: 'Montly',\n",
       " 136: 'Payroll',\n",
       " 137: 'Deduction',\n",
       " 138: 'MRI',\n",
       " 139: 'OF',\n",
       " 140: 'THE',\n",
       " 141: 'LEFT',\n",
       " 142: 'WRIST',\n",
       " 143: 'WITHOUT',\n",
       " 144: 'CONTRAST',\n",
       " 145: 'COMPARISON',\n",
       " 146: 'None',\n",
       " 147: 'These',\n",
       " 148: 'results',\n",
       " 149: 'were',\n",
       " 150: 'faxed',\n",
       " 151: 'Gelovich',\n",
       " 152: 'signed',\n",
       " 153: 'by',\n",
       " 154: 'Stephen',\n",
       " 155: 'Bravo',\n",
       " 156: 'Dependent',\n",
       " 157: 'Detail',\n",
       " 158: 'Billed',\n",
       " 159: 'Amounts',\n",
       " 160: 'Contract',\n",
       " 161: 'Adjustment',\n",
       " 162: 'Allowed',\n",
       " 163: 'Amount',\n",
       " 164: 'Covered',\n",
       " 165: 'Reason',\n",
       " 166: 'Deductible',\n",
       " 167: 'Other',\n",
       " 168: 'Carrier',\n",
       " 169: 'Paid',\n",
       " 170: 'Patient',\n",
       " 171: 'Responsibility',\n",
       " 172: 'Important',\n",
       " 173: 'about',\n",
       " 174: 'Your',\n",
       " 175: 'Appeal',\n",
       " 176: 'Rights',\n",
       " 177: 'All',\n",
       " 178: 'Languages',\n",
       " 179: 'Contact',\n",
       " 180: 'Did',\n",
       " 181: 'You',\n",
       " 182: 'Know',\n",
       " 183: 'Specialty',\n",
       " 184: 'Orthopedic',\n",
       " 185: 'Surgeon',\n",
       " 186: 'Zachary',\n",
       " 187: 'Jager',\n",
       " 188: 'Unknown',\n",
       " 189: 'Kari',\n",
       " 190: 'Lund',\n",
       " 191: 'Orthopedist',\n",
       " 192: 'Dan',\n",
       " 193: 'Palmer',\n",
       " 194: 'On',\n",
       " 195: '&',\n",
       " 196: 'May',\n",
       " 197: 'Spouse',\n",
       " 198: 'Child',\n",
       " 199: 'BLACK',\n",
       " 200: 'HILLS',\n",
       " 201: 'ORTHOPEDIC',\n",
       " 202: 'CENTER',\n",
       " 203: 'PC',\n",
       " 204: 'LAST',\n",
       " 205: 'PMT',\n",
       " 206: 'AMOUNT',\n",
       " 207: 'DUE',\n",
       " 208: 'DATE',\n",
       " 209: 'PAGE',\n",
       " 210: 'STATEMENT',\n",
       " 211: 'Ins',\n",
       " 212: 'Description',\n",
       " 213: 'E',\n",
       " 214: 'm',\n",
       " 215: 'New',\n",
       " 216: 'Moderat',\n",
       " 217: 'S',\n",
       " 218: 'Clo',\n",
       " 219: 'Tx',\n",
       " 220: 'Phalangealfx',\n",
       " 221: 'Finger',\n",
       " 222: 'Splint',\n",
       " 223: 'Offic',\n",
       " 224: 'Cons',\n",
       " 225: 'Moderate',\n",
       " 226: 'Sever',\n",
       " 227: 'Rad',\n",
       " 228: 'Exam',\n",
       " 229: 'Mini',\n",
       " 230: 'Views',\n",
       " 231: 'Applic',\n",
       " 232: 'Hand',\n",
       " 233: 'Lower',\n",
       " 234: 'Forearm',\n",
       " 235: 'Fiberglass',\n",
       " 236: 'gauntlet',\n",
       " 237: 'Cast',\n",
       " 238: 'Yrs',\n",
       " 239: 'Charge',\n",
       " 240: 'Pmt',\n",
       " 241: 'Pat',\n",
       " 242: 'Adjust',\n",
       " 243: 'Days',\n",
       " 244: 'Balance',\n",
       " 245: 'Pending',\n",
       " 246: 'Now',\n",
       " 247: 'Due',\n",
       " 248: 'Message',\n",
       " 249: 'Account',\n",
       " 250: 'Statement',\n",
       " 251: 'Billing',\n",
       " 252: 'Questions',\n",
       " 253: 'Choice',\n",
       " 254: 'Health',\n",
       " 255: 'Administrators',\n",
       " 256: 'Forwarding',\n",
       " 257: 'Service',\n",
       " 258: 'Requested',\n",
       " 259: 'REGIONAL',\n",
       " 260: 'HEALTH',\n",
       " 261: 'INC',\n",
       " 262: 'Participant',\n",
       " 263: 'ID',\n",
       " 264: 'Original',\n",
       " 265: 'Print',\n",
       " 266: 'Website',\n",
       " 267: 'DEA',\n",
       " 268: 'By',\n",
       " 269: 'Plan',\n",
       " 270: 'DEDUCTIBLE',\n",
       " 271: 'OUT',\n",
       " 272: 'POCKET',\n",
       " 273: 'Regional',\n",
       " 274: 'Inc',\n",
       " 275: 'Sign',\n",
       " 276: 'up',\n",
       " 277: 'paperless',\n",
       " 278: 'Individual',\n",
       " 279: 'Family',\n",
       " 280: 'Out',\n",
       " 281: 'Network',\n",
       " 282: 'Karl',\n",
       " 283: 'Services',\n",
       " 284: 'exam',\n",
       " 285: 'hand',\n",
       " 286: 'Modifiers',\n",
       " 287: 'TC',\n",
       " 288: 'RT',\n",
       " 289: 'Appeals',\n",
       " 290: 'This',\n",
       " 291: 'Qualified',\n",
       " 292: 'sign',\n",
       " 293: 'language',\n",
       " 294: 'interpreters',\n",
       " 295: 'written',\n",
       " 296: 'in',\n",
       " 297: 'other',\n",
       " 298: 'languages',\n",
       " 299: 'Jacquelin',\n",
       " 300: 'Brainard',\n",
       " 301: 'Compliance',\n",
       " 302: 'Officer',\n",
       " 303: 'or',\n",
       " 304: 'mail',\n",
       " 305: 'phone',\n",
       " 306: 'Department',\n",
       " 307: 'Human',\n",
       " 308: 'Complaint',\n",
       " 309: 'forms',\n",
       " 310: 'are',\n",
       " 311: 'available',\n",
       " 312: 'EXPLANATION',\n",
       " 313: 'BENEFITS',\n",
       " 314: 'Retain',\n",
       " 315: 'For',\n",
       " 316: 'Tax',\n",
       " 317: 'Purposes',\n",
       " 318: 'Status',\n",
       " 319: 'Period',\n",
       " 320: 'Totals',\n",
       " 321: 'DAKOTA',\n",
       " 322: 'Automated',\n",
       " 323: 'Attendant',\n",
       " 324: 'hours',\n",
       " 325: 'a',\n",
       " 326: 'day',\n",
       " 327: 'Payments',\n",
       " 328: 'Please',\n",
       " 329: 'Call',\n",
       " 330: 'Upon',\n",
       " 331: 'Receipt',\n",
       " 332: 'Pay',\n",
       " 333: 'Online',\n",
       " 334: '|',\n",
       " 335: 'Update',\n",
       " 336: 'Info',\n",
       " 337: 'See',\n",
       " 338: 'Details',\n",
       " 339: 'Back',\n",
       " 340: 'SHOW',\n",
       " 341: 'PAID',\n",
       " 342: 'HERE',\n",
       " 343: 'MAKE',\n",
       " 344: 'CHECKS',\n",
       " 345: 'TO',\n",
       " 346: 'INSUR',\n",
       " 347: 'PENDING',\n",
       " 348: 'PATIENT',\n",
       " 349: 'BALANCE',\n",
       " 350: 'EXAM',\n",
       " 351: 'HAND',\n",
       " 352: 'THORAC',\n",
       " 353: 'SPINE',\n",
       " 354: 'COMMERCIAL',\n",
       " 355: 'NON',\n",
       " 356: 'ALLOWED',\n",
       " 357: 'CT',\n",
       " 358: 'ABD',\n",
       " 359: 'PELV',\n",
       " 360: 'PAYMENT',\n",
       " 361: 'CHEST',\n",
       " 362: 'VIEWS',\n",
       " 363: 'Summary',\n",
       " 364: 'HARGES',\n",
       " 365: 'Of',\n",
       " 366: 'Today',\n",
       " 367: \"'s\",\n",
       " 368: 'Ethnicity',\n",
       " 369: 'Hispanic',\n",
       " 370: 'Latino',\n",
       " 371: 'Preferred',\n",
       " 372: 'English',\n",
       " 373: 'visit',\n",
       " 374: 'with',\n",
       " 375: 'Suzanne',\n",
       " 376: 'Newsom',\n",
       " 377: 'CNP',\n",
       " 378: '•',\n",
       " 379: 'Lethargy',\n",
       " 380: 'cough',\n",
       " 381: 'Vitals',\n",
       " 382: 'lbs',\n",
       " 383: 'kg',\n",
       " 384: 'Wt',\n",
       " 385: 'Temp',\n",
       " 386: 'F',\n",
       " 387: 'HR',\n",
       " 388: 'Oxygen',\n",
       " 389: 'sat',\n",
       " 390: 'Allergies',\n",
       " 391: 'Amoxicillin',\n",
       " 392: 'rash',\n",
       " 393: 'possible',\n",
       " 394: 'hives',\n",
       " 395: 'Active',\n",
       " 396: 'Diagnoses',\n",
       " 397: 'Include',\n",
       " 398: 'Acute',\n",
       " 399: 'frontal',\n",
       " 400: 'sinusitis',\n",
       " 401: 'unspecified',\n",
       " 402: 'Dizziness',\n",
       " 403: 'giddiness',\n",
       " 404: 'Medication',\n",
       " 405: 'List',\n",
       " 406: 'medications',\n",
       " 407: 'you',\n",
       " 408: 'Taking',\n",
       " 409: 'Zyrtec',\n",
       " 410: 'Childrens',\n",
       " 411: 'Allergy',\n",
       " 412: 'Notes',\n",
       " 413: 'Tests',\n",
       " 414: 'Labs',\n",
       " 415: 'Illumigene',\n",
       " 416: 'MYCO',\n",
       " 417: 'http',\n",
       " 418: 'BASIC',\n",
       " 419: 'METABOLIC',\n",
       " 420: 'SODIUM',\n",
       " 421: 'Range',\n",
       " 422: 'POTASSIUM',\n",
       " 423: 'CHLORIDE',\n",
       " 424: 'GLUCOSE',\n",
       " 425: 'BUN',\n",
       " 426: 'CREATININE',\n",
       " 427: 'CALCIUM',\n",
       " 428: 'CREA',\n",
       " 429: 'RATIO',\n",
       " 430: 'Ratio',\n",
       " 431: 'ANION',\n",
       " 432: 'GAP',\n",
       " 433: 'Calc',\n",
       " 434: 'CBC',\n",
       " 435: 'DIFF',\n",
       " 436: 'WBC',\n",
       " 437: 'RBC',\n",
       " 438: 'HGB',\n",
       " 439: 'HCT',\n",
       " 440: 'MCV',\n",
       " 441: 'fL',\n",
       " 442: 'MCH',\n",
       " 443: 'pg',\n",
       " 444: 'MCHC',\n",
       " 445: 'MPV',\n",
       " 446: 'PLATELETS',\n",
       " 447: 'NEUTROPHILS',\n",
       " 448: 'LYMPHOCYTES',\n",
       " 449: 'MONOCYTES',\n",
       " 450: 'Conditions',\n",
       " 451: 'Problem',\n",
       " 452: 'Idiopathic',\n",
       " 453: 'urticaria',\n",
       " 454: 'document',\n",
       " 455: 'wish',\n",
       " 456: 'keep',\n",
       " 457: 'Policyholder',\n",
       " 458: 'Owner',\n",
       " 459: 'Eastside',\n",
       " 460: 'Jasminder',\n",
       " 461: 'Singh',\n",
       " 462: 'Dev',\n",
       " 463: 'PA',\n",
       " 464: 'EXCUSE',\n",
       " 465: 'east',\n",
       " 466: 'side',\n",
       " 467: 'medical',\n",
       " 468: 'center',\n",
       " 469: 'April',\n",
       " 470: 'Weekly',\n",
       " 471: 'DOB',\n",
       " 472: 'Ph',\n",
       " 473: 'MR',\n",
       " 474: 'Primary',\n",
       " 475: 'Thoracic',\n",
       " 476: 'Strain',\n",
       " 477: 'have',\n",
       " 478: 'strained',\n",
       " 479: 'your',\n",
       " 480: 'thoracic',\n",
       " 481: 'spine',\n",
       " 482: 'Page',\n",
       " 483: 'IF',\n",
       " 484: 'ANY',\n",
       " 485: 'FOLLOWING',\n",
       " 486: 'OCCURS',\n",
       " 487: 'feel',\n",
       " 488: 'weakness',\n",
       " 489: 'arms',\n",
       " 490: 'legs',\n",
       " 491: 'severe',\n",
       " 492: 'increase',\n",
       " 493: 'pain',\n",
       " 494: 'Lumbosacral',\n",
       " 495: 'weak',\n",
       " 496: 'becomes',\n",
       " 497: 'more',\n",
       " 498: 'Follow',\n",
       " 499: 'Up',\n",
       " 500: 'What',\n",
       " 501: 'To',\n",
       " 502: 'Do',\n",
       " 503: 'Take',\n",
       " 504: 'all',\n",
       " 505: 'as',\n",
       " 506: 'directed',\n",
       " 507: 'Additional',\n",
       " 508: 'Prescriptions',\n",
       " 509: 'Written',\n",
       " 510: 'Prescriber',\n",
       " 511: 'Paper',\n",
       " 512: 'Prescription',\n",
       " 513: 'given',\n",
       " 514: 'patient',\n",
       " 515: 'Preventative',\n",
       " 516: 'Instructions',\n",
       " 517: 'knee',\n",
       " 518: 'injury',\n",
       " 519: 'David',\n",
       " 520: 'Bruce',\n",
       " 521: 'Identiﬁer',\n",
       " 522: 'June',\n",
       " 523: 'Explanation',\n",
       " 524: 'Gap',\n",
       " 525: 'no',\n",
       " 526: 'concussion',\n",
       " 527: 'Assistant',\n",
       " 528: 'devin',\n",
       " 529: 'conrad',\n",
       " 530: 'September',\n",
       " 531: 'ACCIDENT',\n",
       " 532: 'CLAIM',\n",
       " 533: 'FORM',\n",
       " 534: 'ATTENDING',\n",
       " 535: 'PHYSICIAN',\n",
       " 536: 'PLEASE',\n",
       " 537: 'PRINT',\n",
       " 538: 'PART',\n",
       " 539: 'I',\n",
       " 540: 'BE',\n",
       " 541: 'COMPLETED',\n",
       " 542: 'BY',\n",
       " 543: 'first',\n",
       " 544: 'unable',\n",
       " 545: 'work',\n",
       " 546: 'Expected',\n",
       " 547: 'Delivery',\n",
       " 548: 'Actual',\n",
       " 549: 'Unable',\n",
       " 550: 'Vaginal',\n",
       " 551: 'per',\n",
       " 552: 'Continued',\n",
       " 553: 'Facility',\n",
       " 554: 'State',\n",
       " 555: 'Zip',\n",
       " 556: 'Performed',\n",
       " 557: 'ICD',\n",
       " 558: 'Attending',\n",
       " 559: 'Degree',\n",
       " 560: 'A',\n",
       " 561: 'check',\n",
       " 562: 'type',\n",
       " 563: 'claim',\n",
       " 564: 'filing',\n",
       " 565: 'B',\n",
       " 566: 'About',\n",
       " 567: 'Suffix',\n",
       " 568: 'MI',\n",
       " 569: 'Spanish',\n",
       " 570: 'Short',\n",
       " 571: 'Term',\n",
       " 572: 'Disability',\n",
       " 573: 'Long',\n",
       " 574: 'Life',\n",
       " 575: 'Insurance',\n",
       " 576: 'Voluntary',\n",
       " 577: 'Was',\n",
       " 578: 'this',\n",
       " 579: 'motor',\n",
       " 580: 'vehicle',\n",
       " 581: 'accident',\n",
       " 582: 'Physicians',\n",
       " 583: 'Hospitals',\n",
       " 584: 'Considerations',\n",
       " 585: 'Male',\n",
       " 586: 'Female',\n",
       " 587: 'Surgical',\n",
       " 588: 'CPT',\n",
       " 589: 'X',\n",
       " 590: 'My',\n",
       " 591: 'Member',\n",
       " 592: 'Relationship',\n",
       " 593: 'person',\n",
       " 594: 'Marital',\n",
       " 595: 'Single',\n",
       " 596: 'Occ',\n",
       " 597: 'Title',\n",
       " 598: 'ResinMixer',\n",
       " 599: 'Hire',\n",
       " 600: 'Termination',\n",
       " 601: 'ATW',\n",
       " 602: 'Limitations',\n",
       " 603: 'Permitted',\n",
       " 604: 'Months',\n",
       " 605: 'Office',\n",
       " 606: 'Crane',\n",
       " 607: 'Composites',\n",
       " 608: 'Florence',\n",
       " 609: 'Earn',\n",
       " 610: 'Change',\n",
       " 611: 'Leave',\n",
       " 612: 'Absence',\n",
       " 613: 'Record',\n",
       " 614: 'Loaded',\n",
       " 615: 'Residence',\n",
       " 616: 'Physical',\n",
       " 617: 'Access',\n",
       " 618: 'Home',\n",
       " 619: 'Supervisor',\n",
       " 620: 'Coverages',\n",
       " 621: 'Product',\n",
       " 622: 'Flex',\n",
       " 623: 'Funding',\n",
       " 624: 'Fully',\n",
       " 625: 'Division',\n",
       " 626: 'PEG',\n",
       " 627: 'Eff',\n",
       " 628: 'Earnings',\n",
       " 629: 'Hourly',\n",
       " 630: 'Mode',\n",
       " 631: 'After',\n",
       " 632: 'Report',\n",
       " 633: 'ASO',\n",
       " 634: 'Self',\n",
       " 635: 'If',\n",
       " 636: 'yes',\n",
       " 637: 'dates',\n",
       " 638: 'admission',\n",
       " 639: 'Treatment',\n",
       " 640: 'Nature',\n",
       " 641: 'estimated',\n",
       " 642: 'duration',\n",
       " 643: 'treatments',\n",
       " 644: 'Job',\n",
       " 645: 'description',\n",
       " 646: 'is',\n",
       " 647: 'attached',\n",
       " 648: 'if',\n",
       " 649: 'checked',\n",
       " 650: 'here',\n",
       " 651: 'address',\n",
       " 652: 'Care',\n",
       " 653: 'DETAILS',\n",
       " 654: 'Dates',\n",
       " 655: 'including',\n",
       " 656: 'Confinement',\n",
       " 657: 'please',\n",
       " 658: 'provide',\n",
       " 659: 'following',\n",
       " 660: 'advice',\n",
       " 661: 'stop',\n",
       " 662: 'working',\n",
       " 663: 'what',\n",
       " 664: 'date',\n",
       " 665: 'Mgmt',\n",
       " 666: 'Svc',\n",
       " 667: 'Applicable',\n",
       " 668: 'Deductions',\n",
       " 669: 'Schedule',\n",
       " 670: 'Per',\n",
       " 671: 'Week',\n",
       " 672: 'Sick',\n",
       " 673: 'Variable',\n",
       " 674: 'Sunday',\n",
       " 675: 'Monday',\n",
       " 676: 'Tuesday',\n",
       " 677: 'Wednesday',\n",
       " 678: 'Thursday',\n",
       " 679: 'Friday',\n",
       " 680: 'Saturday',\n",
       " 681: 'SHORT',\n",
       " 682: 'TERM',\n",
       " 683: 'DISABILITY',\n",
       " 684: 'Hospitalized',\n",
       " 685: 'explain',\n",
       " 686: 'last',\n",
       " 687: 'office',\n",
       " 688: 'next',\n",
       " 689: 'Height',\n",
       " 690: 'Weight',\n",
       " 691: 'Secondary',\n",
       " 692: 'Has',\n",
       " 693: 'been',\n",
       " 694: 'hospitalized',\n",
       " 695: 'performed',\n",
       " 696: 'procedure',\n",
       " 697: 'was',\n",
       " 698: 'Functional',\n",
       " 699: 'Capacity',\n",
       " 700: 'Restrictions',\n",
       " 701: 'ELIZABETH',\n",
       " 702: 'EDGEWOOD',\n",
       " 703: 'FACESHEET',\n",
       " 704: 'MRN',\n",
       " 705: 'Sex',\n",
       " 706: 'Demographics',\n",
       " 707: 'SSN',\n",
       " 708: 'Reg',\n",
       " 709: 'Verified',\n",
       " 710: 'PCP',\n",
       " 711: 'Renew',\n",
       " 712: 'Admission',\n",
       " 713: 'Admitting',\n",
       " 714: 'Larkin',\n",
       " 715: 'John',\n",
       " 716: 'MD',\n",
       " 717: 'Elective',\n",
       " 718: 'Incomplete',\n",
       " 719: 'Area',\n",
       " 720: 'SERVICE',\n",
       " 721: 'AREA',\n",
       " 722: 'EDG',\n",
       " 723: 'SC',\n",
       " 724: 'CRESTVIEW',\n",
       " 725: 'Discharged',\n",
       " 726: 'Confirmed',\n",
       " 727: 'HOSE',\n",
       " 728: 'ital',\n",
       " 729: 'Acct',\n",
       " 730: 'Class',\n",
       " 731: 'Same',\n",
       " 732: 'Guarantor',\n",
       " 733: 'Relation',\n",
       " 734: 'Pt',\n",
       " 735: 'SEH',\n",
       " 736: 'Precert',\n",
       " 737: 'Subscriber',\n",
       " 738: 'Operative',\n",
       " 739: 'Brief',\n",
       " 740: 'Op',\n",
       " 741: 'Note',\n",
       " 742: 'OP',\n",
       " 743: 'Adm',\n",
       " 744: 'continued',\n",
       " 745: 'Author',\n",
       " 746: 'J',\n",
       " 747: 'Filed',\n",
       " 748: 'Editor',\n",
       " 749: 'Elizabeth',\n",
       " 750: 'Healthcare',\n",
       " 751: 'NOTE',\n",
       " 752: 'Body',\n",
       " 753: 'mass',\n",
       " 754: 'index',\n",
       " 755: 'PROCEDURE',\n",
       " 756: 'SURGEON',\n",
       " 757: 'Role',\n",
       " 758: 'ANESTHESIA',\n",
       " 759: 'General',\n",
       " 760: 'SPECIMENS',\n",
       " 761: 'specimens',\n",
       " 762: 'log',\n",
       " 763: 'ESTIMATED',\n",
       " 764: 'BLOOD',\n",
       " 765: 'LOSS',\n",
       " 766: 'PROC',\n",
       " 767: 'COURSE',\n",
       " 768: 'PACU',\n",
       " 769: 'OPERATION',\n",
       " 770: 'Broken',\n",
       " 771: 'big',\n",
       " 772: 'toe',\n",
       " 773: 'foot',\n",
       " 774: 'Todd',\n",
       " 775: 'Francis',\n",
       " 776: 'Podiatrist',\n",
       " 777: 'Ryan',\n",
       " 778: 'Kish',\n",
       " 779: 'Toledo',\n",
       " 780: 'ER',\n",
       " 781: 'Xray',\n",
       " 782: 'July',\n",
       " 783: 'Paramount',\n",
       " 784: 'ProMedica',\n",
       " 785: 'LINE',\n",
       " 786: 'AUTHORIZATION',\n",
       " 787: 'NO',\n",
       " 788: 'CODE',\n",
       " 789: 'MODIFIER',\n",
       " 790: 'DIAGNOSIS',\n",
       " 791: 'EXPLAIN',\n",
       " 792: 'BILLED',\n",
       " 793: 'PARAMOUNT',\n",
       " 794: 'LT',\n",
       " 795: 'Indicates',\n",
       " 796: 'additional',\n",
       " 797: 'information',\n",
       " 798: 'C',\n",
       " 799: 'DPM',\n",
       " 800: 'EMS',\n",
       " 801: 'Christine',\n",
       " 802: 'Nolen',\n",
       " 803: 'Waukesha',\n",
       " 804: 'Memorial',\n",
       " 805: 'Cleaning',\n",
       " 806: 'xray',\n",
       " 807: 'bandage',\n",
       " 808: 'MONTANO',\n",
       " 809: 'CI',\n",
       " 810: 'Web',\n",
       " 811: 'user',\n",
       " 812: 'notes',\n",
       " 813: 'statements',\n",
       " 814: 'PROHEALTH',\n",
       " 815: 'CARE',\n",
       " 816: 'SERVICES',\n",
       " 817: 'GUARANTOR',\n",
       " 818: 'NAME',\n",
       " 819: 'DESCRIPTION',\n",
       " 820: 'PAYMENTS',\n",
       " 821: 'ADJUSTMENTS',\n",
       " 822: 'PATIENTS',\n",
       " 823: 'INVOICE',\n",
       " 824: 'NUMBER',\n",
       " 825: 'Previous',\n",
       " 826: 'CURRENT',\n",
       " 827: 'TOTAL',\n",
       " 828: 'VISIT',\n",
       " 829: 'PAY',\n",
       " 830: 'THIS',\n",
       " 831: 'RETURN',\n",
       " 832: 'PORTION',\n",
       " 833: 'WITH',\n",
       " 834: 'YOUR',\n",
       " 835: 'MASTERCARD',\n",
       " 836: 'DISCOVER',\n",
       " 837: 'VISA',\n",
       " 838: 'Enclosed',\n",
       " 839: 'CHECK',\n",
       " 840: 'PAYABLE',\n",
       " 841: 'EMERGENCY',\n",
       " 842: 'MEDICAL',\n",
       " 843: 'ASSOCIATES',\n",
       " 844: 'PHONE',\n",
       " 845: 'ADDRESSEE',\n",
       " 846: 'INDUSTRIAL',\n",
       " 847: 'LOOP',\n",
       " 848: 'ACCOUNT',\n",
       " 849: \"'S\",\n",
       " 850: 'DEPT',\n",
       " 851: 'PPO',\n",
       " 852: 'ADJ',\n",
       " 853: 'UMR',\n",
       " 854: 'FISERV',\n",
       " 855: 'WI',\n",
       " 856: 'ON',\n",
       " 857: 'OVER',\n",
       " 858: 'DAYS',\n",
       " 859: 'STMT',\n",
       " 860: 'DOCTOR',\n",
       " 861: 'LEGEND',\n",
       " 862: 'NOLEN',\n",
       " 863: 'CHRISTINE',\n",
       " 864: 'D',\n",
       " 865: 'COMMENTS',\n",
       " 866: 'PRIMARY',\n",
       " 867: 'SECONDARY',\n",
       " 868: 'Concussion',\n",
       " 869: 'Souha',\n",
       " 870: 'Hakim',\n",
       " 871: 'MedExpress',\n",
       " 872: 'Codes',\n",
       " 873: 'Urgent',\n",
       " 874: 'Clairn',\n",
       " 875: 'ME',\n",
       " 876: 'Seen',\n",
       " 877: 'Vijay',\n",
       " 878: 'Patel',\n",
       " 879: 'Holder',\n",
       " 880: 'Qty',\n",
       " 881: 'Clinical',\n",
       " 882: 'Chief',\n",
       " 883: 'Penicillins',\n",
       " 884: 'Rash',\n",
       " 885: 'Taken',\n",
       " 886: 'BP',\n",
       " 887: 'mmHg',\n",
       " 888: 'PULSE',\n",
       " 889: 'bpm',\n",
       " 890: 'RESP',\n",
       " 891: 'TEMP',\n",
       " 892: 'WEIGHT',\n",
       " 893: 'lb',\n",
       " 894: 'ft',\n",
       " 895: 'BMI',\n",
       " 896: 'SAT',\n",
       " 897: 'Current',\n",
       " 898: 'Meds',\n",
       " 899: 'ACTIVE',\n",
       " 900: 'albuterol',\n",
       " 901: 'sulfate',\n",
       " 902: 'Encounter',\n",
       " 903: 'Progress',\n",
       " 904: 'none',\n",
       " 905: 'Subjective',\n",
       " 906: 'History',\n",
       " 907: 'provided',\n",
       " 908: 'dad',\n",
       " 909: 'interpreter',\n",
       " 910: 'used',\n",
       " 911: 'presents',\n",
       " 912: 'urgent',\n",
       " 913: 'care',\n",
       " 914: 'Review',\n",
       " 915: 'Systems',\n",
       " 916: 'Cardiovascular',\n",
       " 917: 'Negative',\n",
       " 918: 'chest',\n",
       " 919: 'Skin',\n",
       " 920: 'Neurological',\n",
       " 921: 'headaches',\n",
       " 922: 'Objective',\n",
       " 923: 'HENT',\n",
       " 924: 'Right',\n",
       " 925: 'Ear',\n",
       " 926: 'Tympanic',\n",
       " 927: 'membrane',\n",
       " 928: 'normal',\n",
       " 929: 'Nose',\n",
       " 930: 'Oropharynx',\n",
       " 931: 'clear',\n",
       " 932: 'Eyes',\n",
       " 933: 'Conjunctivae',\n",
       " 934: 'EOM',\n",
       " 935: 'Neck',\n",
       " 936: 'supple',\n",
       " 937: 'rigidity',\n",
       " 938: 'murmur',\n",
       " 939: 'heard',\n",
       " 940: 'Lymphadenopathy',\n",
       " 941: 'He',\n",
       " 942: 'has',\n",
       " 943: 'cervical',\n",
       " 944: 'adenopathy',\n",
       " 945: 'alert',\n",
       " 946: 'warm',\n",
       " 947: 'noted',\n",
       " 948: 'Assessment',\n",
       " 949: 'advise',\n",
       " 950: 'SS',\n",
       " 951: 'Penobscot',\n",
       " 952: 'Community',\n",
       " 953: 'Suite',\n",
       " 954: 'Medicine',\n",
       " 955: 'Mental',\n",
       " 956: 'FAX',\n",
       " 957: 'Transmission',\n",
       " 958: 'Sheet',\n",
       " 959: 'FROM',\n",
       " 960: 'Ext',\n",
       " 961: 'number',\n",
       " 962: 'pages',\n",
       " 963: 'cover',\n",
       " 964: 'page',\n",
       " 965: 'Thank',\n",
       " 966: 'Revised',\n",
       " 967: 'Imaging',\n",
       " 968: 'MaineCare',\n",
       " 969: 'FQHC',\n",
       " 970: 'Low',\n",
       " 971: 'JT',\n",
       " 972: 'Rt',\n",
       " 973: 'Erin',\n",
       " 974: 'Barker',\n",
       " 975: 'Joseph',\n",
       " 976: 'Ordering',\n",
       " 977: 'BARKER',\n",
       " 978: 'ERIN',\n",
       " 979: 'RIGHT',\n",
       " 980: 'KNEE',\n",
       " 981: 'INTERCONDYLAR',\n",
       " 982: 'SPACE',\n",
       " 983: 'ACL',\n",
       " 984: 'PCL',\n",
       " 985: 'intact',\n",
       " 986: 'Unremarkable',\n",
       " 987: 'marrow',\n",
       " 988: 'signal',\n",
       " 989: 'T',\n",
       " 990: 'DICTATION',\n",
       " 991: 'LOCATION',\n",
       " 992: 'MPSYNERNET',\n",
       " 993: 'Reading',\n",
       " 994: 'KASPER',\n",
       " 995: 'JARED',\n",
       " 996: 'Down',\n",
       " 997: 'East',\n",
       " 998: 'Orthopedics',\n",
       " 999: 'Sports',\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_word_tokens=len(sorted(list(word2int)))\n",
    "num_char_tokens=len(sorted(list(char2int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecotrize hierarichal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_char_input_data, decoder_word_input_data, decoder_word_target_data = vectorize_hier_data(input_texts, \n",
    "                                                                                                target_texts, \n",
    "                                                                                                max_words_seq_len, \n",
    "                                                                                                max_chars_seq_len, \n",
    "                                                                                                num_char_tokens, \n",
    "                                                                                                num_word_tokens, \n",
    "                                                                                                word2int, \n",
    "                                                                                                char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Hierarichal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 126)         15876     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, None, 512), (None 784384    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 800,260\n",
      "Trainable params: 784,384\n",
      "Non-trainable params: 15,876\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_word_embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder-decoder  model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 11, 20)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 11, 512)      800260      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 11, 512), (N 1574912     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 11, 1024)     3591168     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 11, 512), (N 3147776     embedding_3[0][0]                \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 11, 11)       0           lstm_4[0][0]                     \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 11, 11)       0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 11, 512)      0           activation_1[0][0]               \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 1024)     0           dot_4[0][0]                      \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11, 3507)     3594675     concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,708,791\n",
      "Trainable params: 12,692,915\n",
      "Non-trainable params: 15,876\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:73: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = build_hier_model(encoder_word_embedding_model=encoder_word_embedding_model, \n",
    "                              max_words_seq_len=max_words_seq_len,\n",
    "                              max_char_seq_len=max_chars_seq_len,\n",
    "                              num_word_tokens=num_word_tokens,\n",
    "                              num_char_tokens=num_char_tokens, \n",
    "                              latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 11, 20)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 11, 512)      800260      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 11, 512), (N 1574912     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 2,375,172\n",
      "Trainable params: 2,359,296\n",
      "Non-trainable params: 15,876\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 11, 1024)     3591168     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 11, 512), (N 3147776     embedding_3[0][0]                \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 11, 512)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 11, 11)       0           lstm_4[1][0]                     \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 11, 11)       0           dot_3[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 11, 512)      0           activation_1[1][0]               \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 1024)     0           dot_4[1][0]                      \n",
      "                                                                 lstm_4[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11, 3507)     3594675     concatenate_6[1][0]              \n",
      "==================================================================================================\n",
      "Total params: 10,333,619\n",
      "Trainable params: 10,333,619\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Hierarichal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7104 samples, validate on 1777 samples\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/Variable_14/Assign (defined at /opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:400)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_14, training/Adam/zeros_14)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/Variable_14/Assign', defined at:\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-86cc20843ace>\", line 18, in <module>\n    shuffle=True)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1008, in fit\n    self._make_train_function()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 702, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 400, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/Variable_14/Assign (defined at /opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:400)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_14, training/Adam/zeros_14)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/Variable_14/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_14, training/Adam/zeros_14)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-86cc20843ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     callbacks.set_params({\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/Variable_14/Assign (defined at /opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:400)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_14, training/Adam/zeros_14)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/Variable_14/Assign', defined at:\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-86cc20843ace>\", line 18, in <module>\n    shuffle=True)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1008, in fit\n    self._make_train_function()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 702, in zeros\n    return variable(v, dtype=dtype, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 400, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1481, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/elsallab/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[512,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/Variable_14/Assign (defined at /opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:400)  = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/Variable_14, training/Adam/zeros_14)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_hier_model-{}-{}.hdf5\".format(max_words_seq_len,max_chars_seq_len) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "model.fit([encoder_char_input_data, decoder_word_input_data], decoder_word_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decode_gt_sequence(decoder_word_input_data[idx:idx+1], int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(input_texts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lst =  word_tokenize(target_texts[idx])\n",
    "words_lst.insert(0, '\\t')\n",
    "words_lst.append('\\n')\n",
    "words_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_gt_sequence(np.argmax(decoder_word_target_data[idx:idx+1], axis=-1), int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict([encoder_char_input_data[idx:idx+1], decoder_word_input_data[idx-1:idx]])\n",
    "y.shape\n",
    "#sampled_token_index = np.argmax(y[0, -1, :])\n",
    "d = np.argmax(y, axis=-1)\n",
    "d.shape\n",
    "decode_gt_sequence(d, int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = encoder_char_input_data[idx:idx+1]\n",
    "decoded_sentence, _ = decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_word_tokens, int2word)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_char_input_data[seq_index: seq_index + 1]\n",
    "    target_seq = np.argmax(decoder_word_target_data[seq_index: seq_index + 1], axis=-1)\n",
    "    #print(target_seq)\n",
    "    \n",
    "    decoded_sentence, _ = decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_word_tokens, int2word)\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from val data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_char_input_data[seq_index: seq_index + 1]\n",
    "    target_seq = np.argmax(decoder_word_target_data[seq_index: seq_index + 1], axis=-1)\n",
    "    #print(target_seq)\n",
    "    \n",
    "    decoded_sentence, _ = decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_word_tokens, int2word)\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
